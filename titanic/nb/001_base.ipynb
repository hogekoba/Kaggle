{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc \n",
    "\n",
    "# 分布確認\n",
    "import ydata_profiling as pdp\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 前処理\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# バリデーション\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# モデリング: lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# matplotilbで日本語表示したい場合はこれをinstallしてインポートする\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ\n",
    "df_train = pd.read_csv(\"../data/input/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータ\n",
    "df_test = pd.read_csv(\"../data/input/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "レコード数: 891\n",
      "カラム数: 12\n",
      "(418, 11)\n",
      "レコード数: 418\n",
      "カラム数: 11\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(\"レコード数:\", len(df_train))\n",
    "print(\"カラム数:\", len(df_train.columns))\n",
    "\n",
    "print(df_test.shape)\n",
    "print(\"レコード数:\", len(df_test))\n",
    "print(\"カラム数:\", len(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のデータが変数となっている。 Survivedが目的変数。\n",
    "\n",
    "PassengerId – 乗客識別ユニークID\n",
    "Survived – 生存フラグ（0=死亡、1=生存）\n",
    "Pclass – チケットクラス (1=1等, 2, 3)\n",
    "Name – 乗客の名前\n",
    "Sex – 性別（male=男性、female＝女性）\n",
    "Age – 年齢\n",
    "SibSp – タイタニックに同乗している兄弟/配偶者の数。兄弟（Siblings）や配偶者（Spouses）\n",
    "parch – タイタニックに同乗している親/子供の数\n",
    "ticket – チケット番号\n",
    "fare – 料金\n",
    "cabin – 客室番号\n",
    "Embarked – 出港地（タイタニックへ乗った港）C=シェルブール、Q=クイーンズタウン、S=サウサンプトン)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ型の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計量の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>418.0</td>\n",
       "      <td>1100.500000</td>\n",
       "      <td>120.810458</td>\n",
       "      <td>892.00</td>\n",
       "      <td>996.2500</td>\n",
       "      <td>1100.5000</td>\n",
       "      <td>1204.75</td>\n",
       "      <td>1309.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>418.0</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>332.0</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.17</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>39.00</td>\n",
       "      <td>76.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>418.0</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>418.0</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>417.0</td>\n",
       "      <td>35.627188</td>\n",
       "      <td>55.907576</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.50</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count         mean         std     min       25%        50%  \\\n",
       "PassengerId  418.0  1100.500000  120.810458  892.00  996.2500  1100.5000   \n",
       "Pclass       418.0     2.265550    0.841838    1.00    1.0000     3.0000   \n",
       "Age          332.0    30.272590   14.181209    0.17   21.0000    27.0000   \n",
       "SibSp        418.0     0.447368    0.896760    0.00    0.0000     0.0000   \n",
       "Parch        418.0     0.392344    0.981429    0.00    0.0000     0.0000   \n",
       "Fare         417.0    35.627188   55.907576    0.00    7.8958    14.4542   \n",
       "\n",
       "                 75%        max  \n",
       "PassengerId  1204.75  1309.0000  \n",
       "Pclass          3.00     3.0000  \n",
       "Age            39.00    76.0000  \n",
       "SibSp           1.00     8.0000  \n",
       "Parch           0.00     9.0000  \n",
       "Fare           31.50   512.3292  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.isnull\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "df_test.isnull\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"df_train.isnull\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\ndf_test.isnull\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの検討\n",
    "データをみてどの説明変数を使うかを検討する\n",
    "\n",
    "### 特徴量の確認\n",
    "生存情報と各パラメータの関連を見たい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Samuel Norman Seabornからとっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "男女で死亡率は変わる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Sex', hue=\"Survived\", data=df_train)\n",
    "plt.title(\"性別による生存者数\")\n",
    "plt.legend(\"死亡\", \"生存\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クロス分析による分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.257962</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.811092</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived         0         1\n",
       "Sex                         \n",
       "female    0.257962  0.742038\n",
       "male      0.811092  0.188908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.crosstab(df_train[\"Sex\"], df_train[\"Survived\"], normalize=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  分析の関数化\n",
    "この方法はよさそうなので各変数に対して行ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_croostab(x, hue, data):\n",
    "    sns.countplot(x = x, hue=hue, data=data)\n",
    "    plt.title(x + \"による生存者数\")\n",
    "    plt.show()\n",
    "    display(pd.crosstab(df_train[x], df_train[\"Survived\"], normalize=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHECAYAAAAwOIA0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1jklEQVR4nO3deXxU1f3/8XfCJFGWZCRAYGYCqYY1AVQqpYoQQZaAUH20qcVgBbEuIVWCG4iIKBqkrcgiaC0QQX3I4kIri2xhsyyFSkFWQUM2SEAgC0tCJuf3h1/mZ0zQEIZMcnk9H4/7eDD3nnvu58z3O83bc8/c8TPGGAEAAFiQv68LAAAAuFIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgDwA263W758vFhhYaGOHDnis+sDVkPQAVAjbNmyRfv27fN1GYqKitKUKVOqdO66det08uTJy7r+hx9+qAEDBpTbv2/fPp0/f77MvpKSEq1YsUKS9PzzzysxMVHFxcWaNWuWzp49K0n6zW9+o+XLl19WTUBtRtABcMkOHz6sGTNmlPvDeznGjh2rlJSUSz7P7Xbr1KlT+uabb7R582Z98sknmjZtmtavX1+p8x977DEtWbLkkq/7Y4WFherVq5e2b99+2X392P79+9WlSxfNmjWr3DX/8Ic/aPHixZ59H374oV588UXZbDZJUmpqqho0aOD1moDawubrAgB4x6effqqJEydqz549stls6tKli5577jl17drV69dasmSJXnrpJSUkJHitzwt/mC/F22+/rUcffVSSVL9+fTVr1kz16tXTjh07FB0drV27dv3k+adPn9bs2bM1cODAS772mTNnVFxc7Hm9evVqBQQEqEOHDjp16tRFz6tfv36ZsT766KN6++23y7Xz8/OTJN144406c+aM+vfv7xnrBXa7XQ899JD+9a9/qWnTppK+//+D8ePHKyAgQN9++60KCgrUsGFDHT161HNeUFCQrrvuukseM1AbMaMDWMDChQt1zz33qFu3blq1apUWLVqk+vXrq3v37lqwYIHXr/fvf/9b3bt397zOyMjQXXfdpVtuuUXNmzdXaGiorrvuOgUHB2v16tWV6jMgIKDM65KSEmVmZv7kOX/4wx+0Z88enTp1SgUFBdq1a5eCg4Nlt9v1wQcf/Ow1P/30UwUEBOiOO+6oVI0/lJCQoOuuu86z/e53v9OZM2cUFhZWZv+Pt7Vr15bp58LM2IVt/Pjx6tevn86fP6+TJ08qICBAkZGRmj17drkaRo4cqePHj8tms2nZsmVau3atGjdurC1btujvf/+7Nm7cKElq166dmjVr5tni4uIuebxAbeXHj3oCtV9MTIz8/f21Zs2aMvtfeeUV/eEPf9ANN9zg1etFRUVpyJAhevrppyVJJ06c0LRp0+RyuRQeHq769evL399f/v7+atWqlex2+8/2+bvf/U6HDx9WZGSk0tLStHPnTjVt2lSHDh2qVE1ut1v33nuvli5dqhUrVlRqJismJkbr1q2rVP/16tVTYWFhhcf27NmjLl26aPPmzWrXrl2l+ruYCRMmaPPmzXr//ffVv39/hYSE6OOPP1ZQUFC5tgsWLFBxcbF2796tiRMnqn379nryySdVp04dtWjRQnPmzFFpaan+8Y9/SJJuueUWjRw5UvHx8fL3579zcZUwAGq9m266ydx2220/227GjBmmVatWJigoyLRu3dpMnDjRFBUVGWOM2b17twkKCjJjx471tC8tLTW//vWvTdeuXY3b7TbGGFNSUmJsNpv5/PPPvTqG++67z7Ru3do8+uij5pVXXjHz5883e/furdS5brfbDB482NhsNvOvf/2rUuekpqYaf39/s3XrVnPs2DHPFhkZaSZMmFBm37Fjx8zx48cr7Gf9+vUmPDzcjBkzxpw9e9ZIqnALCQkx6enpnvOefPJJ06JFi3Kb3W431157rWnYsOFF+9qwYYOnny+//NJERkaae+65xzgcDnP99debefPmmaKiItOwYUPz0ksvedqGhoaatWvXVur9AayCoANYwBtvvGEkmfj4eHPgwIEK2zz//POmUaNG5q233jLbt283c+bMMU2aNDHx8fGeNsnJySYwMNDs27fPGGPMzJkzTd26dc3XX3/taZOenm4kmYMHD3p1DA8++KBJSEi45PNKSkrMAw88YPz8/ExKSooxxpji4uKfPOfs2bMmKirKDBo0qNyx1q1bm8mTJ1f6+mPHjjV2u92cOXOmwuNffPGFCQsLMzNnziyz//Dhw+bLL78st40aNcr4+/ubF154wZw8ebLCraSkxJw7d84899xzpmHDhmbVqlVmzJgxZvjw4Wbt2rWmVatWJjk52UgyPXv2NMYYk5ubaySZI0eOVHpsgBUQdACLmDx5sgkJCTF+fn6mb9++ZWZcDh8+bGw2m1mxYkWZc5YsWWIkeYJNSUmJueWWW8wdd9xhjhw5Yux2u5kyZUqZc3bs2GEkmYKCAq/Wn5iYWGHw+CnFxcXm97//vZFkfvGLX5hbb73V1KtXz0gydrvdxMXFmT179pQ778CBAyY8PNxkZmaWO3YpQSc1NdXUqVPHOJ3OCo8/++yzxuFwVGr2q6CgwDz88MPmmmuuMe+9997Pti8pKTEPPfSQZ3zdu3c3b7zxhufYXXfdZQYPHmyCg4NNQUGBWbp0qWnWrFmlxgVYCUEHsJC8vDwzY8YMExUVZSSZ3/zmN+b06dPmnXfeMZJMnTp1ym2SzIcffujp48ItrJYtW5ru3bub0tLSMtfYunWrkWSKi4vNf//7X6/VPmrUKNO3b99Kty8oKDB9+vQxkkyrVq3Mq6++arZt22a+++47c/bsWfO///3P3H///SYkJKTMjNQPzz979my5W1QXu3X141miHTt2mEaNGpmYmJiLBp2goCCzfv36nx3LZ599Zpo3b37RW1WSTPfu3S96/saNG43T6fTcXjTGmO3bt5tDhw6ZAQMGmMmTJ5sRI0aYwYMH/2wtgNUQdAALKi0tNVOmTDGSzNNPP20mTJhgJJlNmzaZXbt2ldtOnjxZ5vzf/e53RpL59NNPy/W9a9cuI8m8//775o477jDGGDNhwgSzdevWS66zpKTEZGVlmezsbDNhwgTzq1/9qtLnduvWzdjtdjN79mxTUlJSYZvS0lLTunVrM3r06AqPT5s27SfDxQ+3lStXes47cOCAadiwoXn00UfNv/71L+N0Oivd17PPPuvpZ9u2baZ3796mbt26pk6dOmXW3vy4zoqCTr169UxQUJCRZAICAkxQUJDx9/c3NpvNtGrVyhjzfYhyOBymWbNmZtGiRZV9ewHLIOgAFnbnnXea6OhoM3PmTCPJbNu27WfP+eKLL4zNZjOdO3c2UVFRnsXKFxw6dMhIMq1bt/Ys/G3Xrp2ZMWNGpes6f/68GTlypLHb7eWCQFRUlJk0aZI5ceLET/axZcsWk56eboqKisywYcNMw4YNTZs2bcz7779fpl2nTp3Mn//850rXVplbV0VFRWbq1KmmtLTUE3RKS0vN+fPny2xhYWHm888/L7PvwqzLn/70J+Pv72+GDBlisrKyTEhIyCUHHWOM+e9//2saNWrkCau//OUvzfz588u06dKliwkLC/vZtUuAFRF0gFrO7XabCRMmmC1btpQ71qVLF9O1a1dz6NAh4+/vX24NTFFRkRk8eLBnrcrp06dNZGSkefjhhz1rdJ577rky5+Tn5xtJJiIiwvNH+4knnjDNmzc3q1atMnl5ecbtdptTp06ZtLQ0s2PHjnJ1/eMf/zBNmjQxGzZsMKdPnzZnz541U6ZMMSEhISY+Pt7Ur1/fNGjQwDz//PMmPz//J8c/ffp0c9NNN5mcnByzadMmEx4ebubOnWuMMWbBggXlZmN+zqUuRr4QdCoSFhZ20WuvWbOmzHsTEhJiAgMDTVBQULnNZrNdNOh07drVdO7c2Xz55ZfmP//5j2nYsGGZ9ywtLc00atTI2Gw289FHH1V6XIBVEHSAWu706dOma9eupm7dumb8+PFmy5YtZtOmTebhhx82fn5+ntsVo0ePNpLM4MGDzdq1a83q1atNTEyMadOmjSksLDTGGJOQkGCaNGnimU15++23jc1mKzcTdN1115WZJTl79qwZMWKECQ0NLTdD4+/vX2525u233zahoaHm3//+tzl37pz57rvvTFxcnOncubNnTDNmzDAul8s88MADPzn+OXPmmObNm5vdu3eb4uJiM3/+fM9CZH9//zJfr66M6go6P1bVGZ2MjAwzbtw443Q6TYMGDcz999/vWVeVl5dnbrzxRnPPPfeYWbNmmaCgoHKzPYDVEXQACyguLjZ/+9vfzE033WTq1atn7Ha76d69u1m+fHmZdu+8845p3769CQwMNE2aNDHDhg3zPB9mxYoVxs/Pr8w3fkpLS03Xrl1NdHR0mVtYSUlJFa7fMcaYnJwc8/XXX5vDhw+bvLy8couZL9T7+OOPm/r163sCkcvlMuvWrSvTrqioyJw+ffonx15SUmJGjBjh+baVJBMWFmYGDRpkNm3aVOE5c+bMqfTanB9uN9xwQ7m+fhx0vvrqK5Oammq2bdtmrr322ko/tyYkJKRKi5ELCwvNW2+9ZcLCwsx9991nHA6H6dKli9m8ebO54YYbTOfOnT3v4d/+9jfj5+dnHn744Qr/7wJYEU9GBuAzpaWlys3Nlb+/vxo3buz5faeqMMbo5MmTCgoKUr169X6y7dmzZ5WXl3fJ17DZbGrUqFGZfZ999pkeffRRz89VpKamauzYsSooKFDLli01d+5c1a1b92f7ttvt+vjjj3XrrbeWO/bWW2/p008/LffzEcnJyXrppZfUpUsXvfTSS7r99ttVWFioHTt26Pnnn5fT6dQ777xT5vrz5s3T9u3b9cYbb1zy+IHaiKADALXUqVOnVFhYKJfLVe5YYWGh6tev74OqgJqFoAMAACyLX3UDAACWRdABAACWRdABAACWRdABAACWZfN1Ab5WWlqq7OxsNWjQ4LK+2goAAKqPMUYFBQVyOBzy97/4vM1VH3Sys7MVHh7u6zIAAEAVZGRkVPiIhQuu+qDToEEDSd+/UcHBwT6uBgAAVEZ+fr7Cw8M9f8cv5qoPOhduVwUHBxN0AACoZX5u2QmLkQEAgGURdAAAgGURdAAAgGVd9Wt0AACoqdxut86fP+/rMnwiICBAderUuex+CDoAANQwxhgdPXpUp06d8nUpPmW329W0adPLes4dQQcAgBrmQshp0qSJ6tate9U90NYYozNnzig3N1eS1KxZsyr3RdABAKAGcbvdnpATGhrq63J85tprr5Uk5ebmqkmTJlW+jcViZAAAapALa3Lq1q3r40p878J7cDnrlAg6AADUQFfb7aqKeOM9IOgAAADLIugAAFCLnDhxQg8++KBatGghh8Ohrl27auXKlVfkWpmZmXK5XNq0adMV6T8mJkYvvvjiFen7AhYjAwBQizz00EMKDAzU/v37FRQUpMWLFys+Pl7bt29XeHi4V6/lcrmUmZnp1T6rGzM6AADUIitXrlR8fLyuueYa+fn56e6779a3337r9ZBjFQQdAABqkY4dO+qVV17R/v37Pfvq1asnSRoyZIiGDBlSpn1ERIRSUlIkSWlpafLz89PBgwd12223KSkpSa1bt9b06dPLnNOyZUu98847nvZpaWn64osvFBQUpO+++87TbuPGjapXr55OnTolt9ut5ORkRUZGyuVyaeDAgTp8+LCn7cmTJ/XAAw+oWbNmioyM1Lhx41RaWurld6c8gg4AALXIe++9J0lq27atYmNjlZqaesl9JCcna/78+Zo8ebIee+wxzZo1y3Ns48aNOn78uOLj48ucc9ttt6lt27ae60tSSkqK4uPjZbfbNWrUKKWkpGjVqlXKyMhQdHS07r77brndbknSsGHDlJubqwMHDmj//v2y2+364osvqvIWXBLW6FSDTk/P9XUJ+IHtf/mjr0sAgCqLiIjQ5s2btXbtWk2fPl133nmnBg8erDlz5lS6jzvuuEMul0vS97NAY8aM0X//+1/dfPPNevfddzVkyJAKn+MzfPhwTZs2TU888YTOnj2rhQsXav369SouLtaMGTOUkpKiiIgISdKECRP097//XRs2bFC7du30ySef6KuvvlKDBg0kSUlJSZo3b97lvyE/g6ADAEAtFBMTo5iYGK1bt069e/fWXXfdVelzf/3rX3v+bbfbFR8fr9mzZ6tt27ZatGiRtm7dWuF58fHxeuaZZ7Rt2zbt379fHTp0UMeOHXX06FGdOXNGSUlJevrpp8uck5aWpmuuuUaSdP3115c5FhwcXOmaq4qgAwBALXLs2DE1btzY87p79+6KiopSdna2rrnmGhUUFHiOFRYW6sSJE+X6+PHPKQwfPlw9e/bUr3/9a/3qV79Sy5YtK7x23bp1NWTIEL333nvav3+/hg8fLkkKCwtT/fr19cEHH6hbt27lzruwVufAgQPq2LGjpO9/zyonJ+cSR3/pWKMDAEAt8d1336l169Z67bXXdO7cOUnffwvr4MGDuvPOO9WxY0d98cUXOnXqlIqKijR8+HCVlJT8bL8dO3ZUmzZt9OyzzyoxMfEn2yYkJOjDDz/U7t279dvf/lbS908wHjFihEaOHKlvvvlGkpSTk6O4uDjt3btXLVq0UN++ffXkk08qPz9fRUVFevLJJ6vlq+sEHQAAaonQ0FCtXLlSGzduVEREhMLDwzV27FgtXLhQUVFRGjp0qGJiYtS6dWvddNNN6t69uzp06FCpvocPH66AgAD169fvJ9u1bNlSHTt21NChQxUQEODZP27cOP3+979XbGysXC6XevTooR49eqht27aSpA8//FDNmzdXq1at1Lp1azVp0kT9+/ev+ptRSX7GGHPFr1KD5efnKyQkRHl5eVfsXiGLkWsWFiMDqMnOnTunb7/9Vr/4xS88a1uuVj/1XlT27zczOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLIIOgAAwLL4UU8AAGqh6n7qflWfKp+SkqK//vWvOnXqlJo1a6bJkyera9euXq7u4pjRAQAAV8S8efM0evRoLVy4UJmZmXrmmWfUv39/zw9/VgeCDgAAuCLGjx+vp556yvPDnnFxcerWrZumT59ebTUQdAAAgNelp6fr0KFDGjBgQJn9AwYM0LJly6qtDoIOAADwuuzsbEmSw+Eos9/pdCorK6va6iDoAAAArwsICJAk+fuXjRp+fn7VWgdBBwAAeJ3L5ZL0/2d2Ljhy5IicTme11UHQAQAAXhcWFqYbb7xRS5cuLbN/5cqVio2NrbY6CDoAAOCKeOaZZzRp0iQdOHBAkrR48WItW7ZMCQkJ1VYDDwwEAABXxKBBg5Sfn6+77rpLhYWFcrlc+uyzzxQZGVltNRB0AACohar6pOLq9sgjj+iRRx7x2fW5dQUAACyLoAMAACyLoAMAACyLoAMAACyLoAMAACyLoAMAACyLoAMAACyLoAMAACyLoAMAACyLJyMDAFALpb/Uvlqv1/yFXZd8TmlpqbZu3aoFCxYoJSVFr7/+uoYMGeL94n4CMzoAAOCKmDNnjh5//HHVrVtXderU8UkNBB0AAHBFDBs2TFu3btWECRNUr149n9RA0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJbFk5EBAKiFqvKkYl9KS0vzyXVrxIzO4cOHZbfbyzwWuqioSKNGjVJkZKQcDocGDhyorKysMudlZWXp3nvvVUREhJxOp5KSklRUVFTN1QMAgJrK50GntLRU999/v1q0aFFmf0JCgjZt2qRt27YpPT1dkZGRio2NldvtliQVFxerV69ecrlcOnjwoHbv3q3t27crKSnJF8MAAAA1kM+Dzquvvqrg4GDdc889nn3p6emeH/+y2+2y2WyaOHGisrOztWTJEknSggULlJOTo+TkZNlsNtntdk2ePFmzZs3S8ePHfTUcAABQg/g06GzdulVTpkzRjBkzyuxfu3atwsLC1KlTJ8++wMBA9e7dW8uWLZMkrVmzRn369FFgYKCnTadOnRQaGqrVq1dXzwAAAECN5rPFyIWFhbrvvvv0xhtvqHnz5mWOZWdny+FwlDvH6XRq//79njbR0dEVtvnxWp4fKioqKrOOJz8/v6pDAADgijHG+LoEn/PGe+CzGZ3ExET98pe/VHx8fLljAQEB8vcvX5qfn98ltalIcnKyQkJCPFt4eHgVqgcA4MoICAiQJJ05c8bHlfjehffgwntSFT6Z0Vm4cKFWrVqlXbsq/mqcy+VSdnZ2uf1HjhyR0+msdJuKjB49WiNHjvS8zs/PJ+wAAGqMOnXqyG63Kzc3V5JUt27dn/2PeKsxxujMmTPKzc2V3W5XnTp1qtyXT4LOkiVLlJWVpYYNG5Y79u6772rBggXKzc3Vzp071aFDB0mS2+1WamqqZz1P37599ac//UklJSWy2b4fxr59+5Sbm6uePXte9NpBQUEKCgq6AqMCAMA7mjZtKkmesHO1stvtnveiqvxMDbkJ+OKLLyotLU0pKSmSpEceeUSHDh3Sxx9/rHr16mnMmDH67LPPtGPHDtlsNpWUlOjGG2/UgAEDNGHCBBUWFuq3v/2tIiMj9dZbb1X6uvn5+QoJCVFeXp6Cg4OvyNg6PT33ivSLqtn+lz/6ugQAqBS3263z58/7ugyfCAgI+MmZnMr+/a6xT0aeOnWqRo0apXbt2sntdqtz585avny5Z/bGZrNp+fLlGj58uMLDw+Xv76+4uDhNnDjRx5UDAOAdderUuazbNqhBMzq+wozO1YcZHQCo/Sr799vnDwwEAAC4Ugg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsgg6AADAsnwWdPLy8vToo4+qefPmat68uTp16qSPP/7Yc7yoqEijRo1SZGSkHA6HBg4cqKysrDJ9ZGVl6d5771VERIScTqeSkpJUVFRU3UMBAAA1lM+CTlxcnIqLi7Vnzx6lp6frL3/5i+6//35t2bJFkpSQkKBNmzZp27ZtSk9PV2RkpGJjY+V2uyVJxcXF6tWrl1wulw4ePKjdu3dr+/btSkpK8tWQAABADeNnjDG+uPCxY8cUEhKiwMBAz76OHTtqyJAh+u1vf6tf/OIX2rp1qzp16iTp+2DjcDg0e/ZsDRw4UO+9956eeOIJHTlyxNPH9u3bdeuttyorK0uNGjWqVB35+fkKCQlRXl6egoODvT9QSZ2enntF+kXVbP/LH31dAgDgMlX277fPZnQaN27sCSjnzp3T22+/rX379qlr165au3atwsLCPCFHkgIDA9W7d28tW7ZMkrRmzRr16dOnTFDq1KmTQkNDtXr16uodDAAAqJFsvi7A5XIpOztbHTp00EcffaRbbrlFq1evlsPhKNfW6XRq//79kqTs7GxFR0dX2ObHa3l+qKioqMw6nvz8fC+MAgAA1EQ+/9ZVZmamvvvuOw0YMECzZs1SYWGhAgIC5O9fvjQ/Pz/PvyvTpiLJyckKCQnxbOHh4Zc/CAAAUCP5POhI0nXXXaeXX35ZOTk5mj59umeW58eOHDkip9MpSZVqU5HRo0crLy/Ps2VkZHhvIAAAoEbxSdApLS3VZ599Vm5/o0aNdPToUfXo0UO5ubnauXOn55jb7VZqaqpiY2MlSX379tWKFStUUlLiabNv3z7l5uaqZ8+eF712UFCQgoODy2wAAMCafBJ0jh07pmHDhmn8+PGe9TKff/65Pv/8c/Xv31+NGzfW0KFDNXLkSOXn58vtdmvMmDGy2+3q16+fJKl///5q0qSJxo4dK7fbrby8PCUmJmro0KGV/sYVAACwNp8EnbCwMG3evFl79uzR9ddfL4fDoVGjRiklJUW9evWSJE2dOlXt27dXu3bt5HK5tHfvXi1fvlw22/frp202m5YvX649e/YoPDxcUVFRat++vaZMmeKLIQEAgBrIZ8/RqSl4js7Vh+foAEDtV+OfowMAAHClEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlVSnonDt37pL2AwAA+EKVgk6rVq3K7Tt16pR69ep12QUBAAB4i+1SGmdkZMgYo5KSEs+/L8jJydH+/fu9XiAAAEBVXVLQGTJkiFJTU+Xn56cWLVqUOVa3bl09/vjjXi0OAADgclxS0Fm9erUkKTo6Wl999dUVKQgAAMBbqrRGh5ADAABqg0ua0fmhZcuWadeuXeW+afXCCy9cdlEAAADeUKWgk5CQoHnz5qlDhw4KDAz07Pfz8yPoAACAGqNKQeejjz7Snj17FB4e7u16AAAAvKZKa3RCQkIIOQAAoMarUtB54IEH9PLLL3u7FgAAAK+q0q2rr776Sv/85z/1/vvvy+FwlDm2Zs0arxQGAABwuaoUdNq0aaM2bdp4uxYAAACvqlLQGTdunLfrAAAA8LoqrdEBAACoDao0o+Pv7y8/P78Kj7nd7ssqCAAAwFuqFHRSU1PLvE5LS1NycrImTZrklaIAAAC8oUpBp3v37uVe33rrrXrsscc0cOBArxQGAABwuby2Rqdly5bau3evt7oDAAC4bFWa0Vm/fn2Z1+fPn9eSJUvUtGlTrxQFAADgDVUKOjExMWVeBwUF6cYbb9Ts2bO9URMAAIBXVCnolJaWersOAAAAr7usNTput1tHjx5VSUmJt+oBAADwmioFHWOMXnjhBdntdjmdTtntdo0ePVrGGG/XBwAAUGVVCjozZszQhx9+qHfffVe7du3SvHnz9Omnn2rKlCnerg8AAKDKqrRGZ+bMmVq+fLmuv/56SVK7du100003qV+/fhoxYoQ36wMAAKiyKgWd/Px8T8i5ICIiQoWFhV4pCgCAqkh/qb2vS8D/af7CLl+XIKmKt66cTqdWr15dZt+6det4jg4AAKhRqjSj89JLL2ngwIF66KGH1LZtWx04cEDvvPOOFi1a5O36AAAAqqxKMzq9evXSJ598or179+r111/Xzp07NX/+fPXp08fb9QEAAFRZlWZ0jh49qrlz52r58uXy9/fX+fPnFRMTo3bt2ikiIsLLJQIAAFRNlWZ0/vznPys8PFx+fn6SpICAAA0bNkyJiYleLQ4AAOByVCnobN68Wa+++qon6EjSgw8+qJ07d3qtMAAAgMtVpaDj7++vc+fOldlXUFDglYIAAAC8pUpB584779TgwYN14sQJSdLJkyc1ZMgQxcbGerU4AACAy1GloDNp0iRlZGSoSZMmatq0qRo3bqysrCy99tpr3q4PAACgyqr0ravQ0FBt2bJFX3zxhdLT09WiRQvddttt3q4NAADgslQp6EiSn5+funbt6s1aAAAAvKpKt64AAABqA4IOAACwLIIOAACwLIIOAACwLIIOAACwLIIOAACwLIIOAACwLIIOAACwLIIOAACwLJ8GndmzZys6OlpOp1Nt2rTRzJkzyxwvKirSqFGjFBkZKYfDoYEDByorK6tMm6ysLN17772KiIiQ0+lUUlKSioqKqnMYAACghvJZ0Jk3b57GjRun+fPnKysrS59++qlefvllvf/++542CQkJ2rRpk7Zt26b09HRFRkYqNjZWbrdbklRcXKxevXrJ5XLp4MGD2r17t7Zv366kpCRfDQsAANQgPgs6mzdv1qRJkxQVFSVJatOmjQYNGqSPPvpIkpSenq6UlBS9/vrrstvtstlsmjhxorKzs7VkyRJJ0oIFC5STk6Pk5GTZbDbZ7XZNnjxZs2bN0vHjx301NAAAUEP4LOi8+eabGjRoUJl9u3btUnBwsCRp7dq1CgsLU6dOnTzHAwMD1bt3by1btkyStGbNGvXp00eBgYGeNp06dVJoaKhWr15d4XWLioqUn59fZgMAANZUIxYjnz9/Xn/+85+1adMmPfXUU5Kk7OxsORyOcm2dTqdnnU5l2vxYcnKyQkJCPFt4eLgXRwIAAGoSnwedw4cP6/bbb9fq1au1ceNGRUdHS5ICAgLk71++PD8/P8+/K9Pmx0aPHq28vDzPlpGR4YVRAACAmsinQWf79u265ZZb1LVrV3355Zfq2LGj55jL5VJ2dna5c44cOSKn01npNj8WFBSk4ODgMhsAALAmnwWdw4cPq1+/fnrzzTf117/+VUFBQWWO9+jRQ7m5udq5c6dnn9vtVmpqqmJjYyVJffv21YoVK1RSUuJps2/fPuXm5qpnz57VMxAAAFBj+SzoPPbYY0pISFBcXFyFxxs3bqyhQ4dq5MiRys/Pl9vt1pgxY2S329WvXz9JUv/+/dWkSRONHTtWbrdbeXl5SkxM1NChQ9WoUaPqHA4AAKiBfBZ0li1bphkzZsjlcpXbLpg6darat2+vdu3ayeVyae/evVq+fLlsNpskyWazafny5dqzZ4/Cw8MVFRWl9u3ba8qUKb4aFgAAqEFsvrqwMeZn2wQFBWny5MmaPHnyRdu4XC4tXrzYm6UBAACL8Pm3rgAAAK4Ugg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsgg4AALAsm68LAKpb+kvtfV0C/k/zF3b5ugQAFseMDgAAsCyfBZ3S0lJt3rxZI0eOVMOGDZWSklLmeFFRkUaNGqXIyEg5HA4NHDhQWVlZZdpkZWXp3nvvVUREhJxOp5KSklRUVFSNowAAADWZz4LOnDlz9Pjjj6tu3bqqU6dOueMJCQnatGmTtm3bpvT0dEVGRio2NlZut1uSVFxcrF69esnlcungwYPavXu3tm/frqSkpOoeCgAAqKF8FnSGDRumrVu3asKECapXr16ZY+np6UpJSdHrr78uu90um82miRMnKjs7W0uWLJEkLViwQDk5OUpOTpbNZpPdbtfkyZM1a9YsHT9+3BdDAgAANUyNXKOzdu1ahYWFqVOnTp59gYGB6t27t5YtWyZJWrNmjfr06aPAwEBPm06dOik0NFSrV6+u9poBAEDNUyO/dZWdnS2Hw1Fuv9Pp1P79+z1toqOjK2zz47U8P1RUVFRmHU9+fr4XKgYAADVRjZzRCQgIkL9/+dL8/PwuqU1FkpOTFRIS4tnCw8Mvv2AAAFAj1cig43K5lJ2dXW7/kSNH5HQ6K92mIqNHj1ZeXp5ny8jI8F7hAACgRqmRQadHjx7Kzc3Vzp07PfvcbrdSU1MVGxsrSerbt69WrFihkpIST5t9+/YpNzdXPXv2vGjfQUFBCg4OLrMBAABrqpFBp3Hjxho6dKhGjhyp/Px8ud1ujRkzRna7Xf369ZMk9e/fX02aNNHYsWPldruVl5enxMREDR06VI0aNfLxCAAAQE1QI4OOJE2dOlXt27dXu3bt5HK5tHfvXi1fvlw22/frp202m5YvX649e/YoPDxcUVFRat++vaZMmeLjygEAQE1RI751lZaWVm5fUFCQJk+erMmTJ1/0PJfLpcWLF1/BygAAQG1WY2d0AAAALhdBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWFaNeGAgANRWnZ6e6+sS8AOfNPB1BahpmNEBAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWRdABAACWZYmgk5KSoujoaLlcLt1yyy3auHGjr0sCAAA1QK0POvPmzdPo0aO1cOFCZWZm6plnnlH//v31zTff+Lo0AADgY7U+6IwfP15PPfWU2rZtK0mKi4tTt27dNH36dB9XBgAAfK1WB5309HQdOnRIAwYMKLN/wIABWrZsmY+qAgAANYXN1wVcjuzsbEmSw+Eos9/pdCorK6vCc4qKilRUVOR5nZeXJ0nKz8+/QlVK7qKzV6xvXLqCALevS8D/uZKfu+rC57tm4fNdc1zpz/eF/o0xP9muVgedgIAASZK/f9mJKT8/v4uek5ycrPHjx5fbHx4e7t3iUGNF+7oA/H/JIb6uABbD57sGqabPd0FBgUJCLn6tWh10XC6XpO9ndiIjIz37jxw5IqfTWeE5o0eP1siRIz2vS0tLdeLECYWGhv5kQII15OfnKzw8XBkZGQoODvZ1OQC8iM/31cUYo4KCgnJ3dX6sVgedsLAw3XjjjVq6dKkef/xxz/6VK1cqNja2wnOCgoIUFBRUZp/dbr+SZaIGCg4O5n8IAYvi8331+KmZnAtq9WJkSXrmmWc0adIkHThwQJK0ePFiLVu2TAkJCT6uDAAA+FqtntGRpEGDBik/P1933XWXCgsL5XK59Nlnn5W5lQUAAK5OtT7oSNIjjzyiRx55xNdloBYICgrSuHHjyt2+BFD78flGRfzMz30vCwAAoJaq9Wt0AAAALoagAwAALIugAwAALIugg6teRESEUlJSfF0GcNXJz89XXFycnE6nWrZs6XlMSHWIiYnRiy++WG3Xg+9Y4ltXAIDaZ+rUqTp06JC+/fZbnTlzhoe34oog6AAAfOLQoUPq0KGDAgMDFRgY6OtyYFHcukKtFBMToxdeeEExMTFq3LixYmJilJmZqfvuu0/NmjXTzTffrJ07d0qSzp8/r2eeeUbNmzeXw+HQvffeq1OnTl207w0bNujWW2+Vw+FQdHS0Pv7442oaFXD1iIuL04IFC7Rw4UK5XC699tprSk5OVmRkpFwulwYOHKjDhw972g8ZMkTDhw/X3XffrbCwMN188836+uuv9cQTT8jpdKp169ZKTU31tDfGaNKkSbr++uvVrFkz9e3bVxkZGRet56uvvlLv3r3lcDjUqlUrzZw584qOH9WHoINa6+9//7umT5+u7OxslZSU6Oabb9aAAQN05MgR3XHHHZ6HSL7//vtav369du7cqUOHDikrK0uvvPJKhX1++eWX6tWrlxITE5Wdna2UlBQ9+OCD+s9//lOdQwMsb+HChYqLi1NcXJwyMzN1/PhxpaSkaNWqVcrIyFB0dLTuvvtuud1uzzlz587ViBEjlJOTo1atWum2225T06ZNlZWVpcTERMXHx+vCo+HWrFmjWbNmaf369crMzFSDBg3K/KDzD2VlZen2229Xz549lZmZqaVLl+rVV1/VRx99VC3vBa4sgg5qrfvuu0/R0dEKCAhQ9+7dFRYWpkGDBkmS+vTpoy+//FLS9/8luGHDBtntdl177bWKi4vTjh07KuzzzTffVM+ePXXfffdJkn75y19q6NChevPNN6tlTMDVqLi4WDNmzNCECRMUEREhPz8/TZgwQRkZGdqwYYOnXa9evRQTEyNJ6tmzp9xut5566ilJ33/mjxw5opycHM/xr776Si6XS3Xq1NHgwYMv+rmfM2eOnE6nnn32Wfn7+ysyMlJPPfWUpk2bdkXHjerBGh3UWj/8deKAgACFhoZ6XgcGBqqoqEiS9PXXX+uVV17R5s2bdfbsWZ0+fVrR0dEV9pmZmanNmzcrIiLCs6+4uPii7QFcvhMnTujMmTNKSkrS008/XeZYWlqa598//sw3aNBAAQEBkuRZ43Pu3DlJUk5OjsaPH69169apoKBAxcXFuuaaayq8fmZmptLS0sp87ktKSlS/fn1vDA8+RtCB5Q0cOFBdu3bVxo0b1ahRI82cOVPz58+vsG1kZKQcDodmz55dzVUCV6+wsDDVr19fH3zwgbp16+aVPocMGaI6depoxYoVcjqdWrZsmR577LEK20ZGRqpz585as2aNV66NmoVbV7C8/Px8RUVFqVGjRjp8+LBmzZqlM2fOVNg2ISFBixYt0qJFi2SMUUlJiaZMmaLk5ORqrhq4evj5+WnEiBEaOXKkvvnmG0nfz8jExcVp7969VeozPz9fLVu2lNPp1LFjxzR16tSLfu7vv/9+7dq1S9OnT5fb7ZYxRvPnz1diYmKVx4Sag6ADy5s7d67efvttORwO/fGPf9Rf//pXHThwQMXFxeXatmvXTsuWLdPUqVPlcDh0ww036H//+58efvhhH1QOXD3GjRun3//+94qNjZXL5VKPHj3Uo0cPtW3btkr9vfnmm9qwYYOaNWum2NhYPffcczp37pyOHj1arm1YWJjWrl2rpUuXqnnz5mrRooUWLFhQ7jYaaid+vRwAAFgWMzoAAMCyCDoAAMCyCDoAAMCyCDoAAMCyCDoAAMCyCDoAAMCyCDoAAMCyCDoAaqUTJ07owQcfVIsWLeRwONS1a1etXLnS12UBqGH4rSsAtdJDDz2kwMBA7d+/X0FBQVq8eLHi4+O1fft2hYeH+7o8ADUET0YGUCs1aNBAH3zwgQYMGODZd/r0adWrV8+HVQGoabh1BaBW6tixo1555RXt37/fs+9CyHG73UpOTlZkZKRcLpcGDhyow4cPS5KWLl2q4OBgpaWlSfr+FpjD4dDixYurfQwArjyCDoBa6b333pMktW3bVrGxsUpNTfUcGzVqlFJSUrRq1SplZGQoOjpad999t9xut/r166ehQ4dq2LBhMsYoMTFR99xzj37zm9/4aigAriBuXQGo1dauXavp06frk08+0eDBg/XOO+/ouuuuU0pKiuLi4iRJpaWlatKkiRYtWqSYmBidO3dOnTt3VuvWrbV371795z//0bXXXuvjkQC4EliMDKBWi4mJUUxMjNatW6fevXvrzjvv1JkzZ5SUlKSnn366TNsLt6uuueYajRo1SvHx8Xr33XcJOYCFMaMDoFY6duyYGjduXGbfzTffrAceeEDPP/+8lixZom7dulV4bl5enm666Sb1799f//znP/W///1Pdru9GqoGUN1YowOg1vnuu+/UunVrvfbaazp37pwkaeXKlTp48KDuvPNOjRgxQiNHjtQ333wjScrJyVFcXJz27t0rSXrkkUfUvXt3TZs2Tbfffrsefvhhn40FwJXFrSsAtU5oaKhWrlypF198UZMnT1ZAQICcTqcWLlyoqKgojRs3Tg0aNFBsbKxOnz6tkJAQJSYmqm3btpo1a5Y2bNig3bt3S5KmTZum6OhozZo1S8OGDfPxyAB4G7euAACAZXHrCgAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWBZBBwAAWNb/AzGh6jcnRuukAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.257962</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.811092</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived         0         1\n",
       "Sex                         \n",
       "female    0.257962  0.742038\n",
       "male      0.811092  0.188908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_croostab(\"Sex\", \"Survived\", df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pclass\n",
    "3等級は生存率が低い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.527174</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757637</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived         0         1\n",
       "Pclass                      \n",
       "1         0.370370  0.629630\n",
       "2         0.527174  0.472826\n",
       "3         0.757637  0.242363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_croostab(\"Pclass\", \"Survived\", df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 年齢\n",
    "ヒストグラムを解析する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ab2436a390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_train[\"Age\"].dropna(), kde=False, bins=30, label=\"全体\")\n",
    "sns.distplot(df_train[df_train[\"Survived\"] == 0].Age.dropna(), kde=False, bins=30, label=\"死亡\")\n",
    "sns.distplot(df_train[df_train[\"Survived\"] == 0].Age.dropna(), kde=False, bins=30, label=\"生存\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初めのBINで生存率高い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CutAge</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.34, 10.368]</th>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10.368, 20.315]</th>\n",
       "      <td>0.617391</td>\n",
       "      <td>0.382609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(20.315, 30.263]</th>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.365217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(30.263, 40.21]</th>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.445161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(40.21, 50.158]</th>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.383721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(50.158, 60.105]</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(60.105, 70.052]</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(70.052, 80.0]</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived                 0         1\n",
       "CutAge                              \n",
       "(0.34, 10.368]    0.406250  0.593750\n",
       "(10.368, 20.315]  0.617391  0.382609\n",
       "(20.315, 30.263]  0.634783  0.365217\n",
       "(30.263, 40.21]   0.554839  0.445161\n",
       "(40.21, 50.158]   0.616279  0.383721\n",
       "(50.158, 60.105]  0.595238  0.404762\n",
       "(60.105, 70.052]  0.764706  0.235294\n",
       "(70.052, 80.0]    0.800000  0.200000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"CutAge\"] = pd.cut(df_train[\"Age\"], 8) # 年齢を8等分した変数を作成\n",
    "display(pd.crosstab(df_train[\"CutAge\"], df_train[\"Survived\"], normalize=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 運賃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cut_Fare</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.512, 51.233]</th>\n",
       "      <td>0.681694</td>\n",
       "      <td>0.318306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(51.233, 102.466]</th>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.660377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(102.466, 153.699]</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(153.699, 204.932]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(204.932, 256.165]</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(256.165, 307.398]</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(461.096, 512.329]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived                   0         1\n",
       "Cut_Fare                              \n",
       "(-0.512, 51.233]    0.681694  0.318306\n",
       "(51.233, 102.466]   0.339623  0.660377\n",
       "(102.466, 153.699]  0.258065  0.741935\n",
       "(153.699, 204.932]  0.000000  1.000000\n",
       "(204.932, 256.165]  0.363636  0.636364\n",
       "(256.165, 307.398]  0.333333  0.666667\n",
       "(461.096, 512.329]  0.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"Cut_Fare\"] = pd.cut(df_train[\"Fare\"], 10) # 年齢を10等分した変数を作成\n",
    "check_croostab(\"Cut_Fare\", \"Survived\", df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 性別は数値でないためOneHotVectorで数値化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male\n",
       "0           0         1\n",
       "1           1         0\n",
       "2           1         0\n",
       "3           1         0\n",
       "4           0         1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = pd.get_dummies(df_train[[\"Sex\"]], dummy_na=False, drop_first=False)\n",
    "df_one = df_one.astype(np.int64)\n",
    "\n",
    "df_sex_test = pd.get_dummies(df_test[[\"Sex\"]], dummy_na=False, drop_first=False)\n",
    "\n",
    "df_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male  Pclass     Fare\n",
       "0           0         1       3   7.2500\n",
       "1           1         0       1  71.2833\n",
       "2           1         0       3   7.9250\n",
       "3           1         0       1  53.1000\n",
       "4           0         1       3   8.0500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.concat([df_one, df_train[[\"Pclass\", \"Fare\"]]], axis=1)\n",
    "y_train = df_train[[\"Survived\"]]\n",
    "id_train = df_train[[\"PassengerId\"]]\n",
    "\n",
    "x_test = pd.concat([df_sex_test, df_test[[\"Pclass\", \"Fare\"]]], axis=1)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検証の方針"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証データ\n",
    "* 交差検証を用いる\n",
    "  * 5分割する。cv (Cross Validation)\n",
    "  * StratifiedKFold.split()の結果は学習用データと検証用データのインデックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  0,   1,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,  15,\n",
       "          16,  18,  19,  20,  21,  22,  23,  24,  25,  27,  28,  30,  31,\n",
       "          32,  33,  35,  36,  37,  39,  40,  41,  42,  43,  44,  46,  47,\n",
       "          49,  50,  51,  52,  53,  54,  58,  59,  60,  63,  64,  65,  66,\n",
       "          67,  68,  69,  71,  73,  74,  75,  76,  77,  78,  81,  82,  84,\n",
       "          85,  86,  87,  88,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "          99, 100, 101, 102, 103, 104, 106, 107, 109, 110, 111, 113, 114,\n",
       "         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130,\n",
       "         131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161,\n",
       "         162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
       "         176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190,\n",
       "         191, 192, 193, 194, 196, 198, 199, 200, 201, 202, 203, 205, 206,\n",
       "         207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 220, 222, 224,\n",
       "         225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 240, 241,\n",
       "         242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 256,\n",
       "         259, 260, 261, 262, 263, 264, 265, 266, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 285, 286, 287,\n",
       "         288, 289, 290, 291, 293, 294, 295, 296, 298, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317,\n",
       "         319, 321, 323, 324, 325, 326, 327, 329, 330, 331, 333, 334, 335,\n",
       "         339, 340, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
       "         355, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368,\n",
       "         370, 371, 372, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384,\n",
       "         386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398,\n",
       "         399, 400, 401, 402, 403, 405, 406, 408, 411, 412, 413, 414, 415,\n",
       "         416, 419, 420, 421, 422, 423, 424, 425, 426, 427, 430, 432, 433,\n",
       "         434, 435, 437, 439, 440, 443, 444, 445, 446, 447, 448, 451, 452,\n",
       "         453, 454, 455, 456, 457, 459, 462, 464, 465, 466, 468, 469, 470,\n",
       "         471, 472, 473, 474, 475, 476, 478, 479, 481, 482, 483, 485, 486,\n",
       "         490, 493, 494, 495, 497, 498, 499, 500, 502, 503, 504, 505, 507,\n",
       "         508, 509, 511, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522,\n",
       "         523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535,\n",
       "         537, 538, 539, 540, 542, 543, 544, 545, 546, 547, 550, 551, 552,\n",
       "         553, 555, 556, 557, 560, 561, 562, 564, 565, 566, 567, 568, 570,\n",
       "         572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "         585, 586, 587, 589, 590, 591, 593, 594, 595, 596, 598, 599, 600,\n",
       "         601, 602, 603, 604, 608, 609, 610, 611, 612, 613, 614, 615, 616,\n",
       "         617, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631,\n",
       "         632, 633, 636, 638, 639, 642, 643, 644, 645, 646, 649, 651, 653,\n",
       "         654, 655, 656, 657, 658, 659, 660, 661, 662, 664, 665, 666, 667,\n",
       "         668, 669, 671, 672, 673, 674, 676, 677, 678, 679, 680, 681, 682,\n",
       "         683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 697,\n",
       "         699, 700, 701, 702, 704, 705, 706, 707, 709, 711, 712, 713, 714,\n",
       "         715, 717, 718, 719, 721, 723, 724, 725, 726, 727, 728, 729, 730,\n",
       "         733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 746,\n",
       "         747, 748, 750, 753, 754, 755, 756, 758, 759, 760, 761, 762, 763,\n",
       "         764, 768, 770, 771, 772, 773, 774, 775, 777, 778, 779, 780, 782,\n",
       "         783, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796,\n",
       "         797, 798, 799, 800, 801, 802, 804, 805, 807, 808, 809, 810, 811,\n",
       "         812, 813, 814, 815, 816, 817, 818, 819, 820, 822, 823, 824, 825,\n",
       "         828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840,\n",
       "         841, 843, 845, 846, 847, 848, 851, 853, 854, 855, 856, 857, 858,\n",
       "         860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 874,\n",
       "         876, 878, 879, 880, 881, 885, 886, 887, 888, 890]),\n",
       "  array([  2,   3,  12,  17,  26,  29,  34,  38,  45,  48,  55,  56,  57,\n",
       "          61,  62,  70,  72,  79,  80,  83,  89, 105, 108, 112, 125, 126,\n",
       "         128, 135, 145, 146, 158, 159, 163, 177, 187, 195, 197, 204, 213,\n",
       "         218, 219, 221, 223, 227, 237, 238, 239, 250, 255, 257, 258, 267,\n",
       "         279, 284, 292, 297, 299, 315, 318, 320, 322, 328, 332, 336, 337,\n",
       "         338, 341, 344, 354, 362, 369, 373, 380, 385, 404, 407, 409, 410,\n",
       "         417, 418, 428, 429, 431, 436, 438, 441, 442, 449, 450, 458, 460,\n",
       "         461, 463, 467, 477, 480, 484, 487, 488, 489, 491, 492, 496, 501,\n",
       "         506, 510, 512, 536, 541, 548, 549, 554, 558, 559, 563, 569, 571,\n",
       "         588, 592, 597, 605, 606, 607, 618, 619, 634, 635, 637, 640, 641,\n",
       "         647, 648, 650, 652, 663, 670, 675, 695, 696, 698, 703, 708, 710,\n",
       "         716, 720, 722, 731, 732, 745, 749, 751, 752, 757, 765, 766, 767,\n",
       "         769, 776, 781, 784, 803, 806, 821, 826, 827, 842, 844, 849, 850,\n",
       "         852, 859, 872, 873, 875, 877, 882, 883, 884, 889])),\n",
       " (array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  12,  17,  18,\n",
       "          20,  21,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
       "          34,  35,  36,  37,  38,  39,  41,  43,  45,  47,  48,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  78,  79,  80,\n",
       "          81,  82,  83,  84,  85,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          96,  98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "         112, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127,\n",
       "         128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141,\n",
       "         142, 143, 145, 146, 148, 149, 150, 153, 154, 155, 156, 157, 158,\n",
       "         159, 160, 161, 162, 163, 164, 165, 166, 169, 170, 172, 173, 175,\n",
       "         177, 179, 180, 181, 183, 184, 186, 187, 189, 190, 191, 192, 194,\n",
       "         195, 196, 197, 198, 199, 200, 202, 203, 204, 207, 208, 209, 211,\n",
       "         212, 213, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227,\n",
       "         228, 229, 230, 231, 234, 235, 237, 238, 239, 240, 241, 242, 244,\n",
       "         246, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "         265, 266, 267, 268, 269, 271, 272, 273, 275, 276, 277, 278, 279,\n",
       "         280, 281, 282, 283, 284, 285, 287, 288, 289, 291, 292, 293, 295,\n",
       "         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309,\n",
       "         310, 311, 313, 315, 317, 318, 319, 320, 322, 324, 326, 327, 328,\n",
       "         329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
       "         343, 344, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
       "         357, 359, 360, 361, 362, 363, 365, 367, 368, 369, 370, 371, 372,\n",
       "         373, 374, 375, 377, 378, 380, 381, 382, 385, 386, 387, 388, 389,\n",
       "         390, 392, 393, 394, 396, 397, 399, 401, 402, 403, 404, 405, 406,\n",
       "         407, 409, 410, 411, 413, 415, 416, 417, 418, 420, 421, 422, 423,\n",
       "         424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 436, 437, 438,\n",
       "         439, 440, 441, 442, 444, 445, 446, 448, 449, 450, 452, 454, 455,\n",
       "         456, 457, 458, 459, 460, 461, 462, 463, 465, 466, 467, 469, 473,\n",
       "         475, 476, 477, 479, 480, 481, 482, 484, 485, 486, 487, 488, 489,\n",
       "         490, 491, 492, 493, 494, 496, 497, 498, 500, 501, 503, 504, 505,\n",
       "         506, 507, 508, 510, 512, 514, 515, 516, 517, 518, 519, 520, 521,\n",
       "         522, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 546, 547, 548, 549, 550, 553, 554,\n",
       "         557, 558, 559, 560, 562, 563, 564, 565, 566, 567, 568, 569, 570,\n",
       "         571, 572, 574, 576, 577, 578, 579, 582, 585, 586, 587, 588, 589,\n",
       "         591, 592, 593, 595, 596, 597, 598, 601, 603, 604, 605, 606, 607,\n",
       "         608, 609, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 624,\n",
       "         625, 626, 627, 628, 629, 631, 634, 635, 636, 637, 638, 639, 640,\n",
       "         641, 642, 643, 645, 647, 648, 649, 650, 652, 653, 654, 655, 656,\n",
       "         658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n",
       "         672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683, 684, 685,\n",
       "         686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698,\n",
       "         699, 700, 701, 703, 704, 706, 707, 708, 710, 711, 712, 714, 715,\n",
       "         716, 718, 719, 720, 721, 722, 723, 724, 726, 727, 729, 730, 731,\n",
       "         732, 733, 734, 735, 736, 738, 739, 741, 743, 745, 747, 749, 751,\n",
       "         752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 763, 764, 765,\n",
       "         766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 780,\n",
       "         781, 782, 784, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795,\n",
       "         796, 797, 798, 800, 801, 803, 804, 805, 806, 807, 809, 810, 811,\n",
       "         812, 813, 814, 815, 818, 819, 820, 821, 822, 823, 824, 825, 826,\n",
       "         827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 838, 839, 840,\n",
       "         842, 843, 844, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856,\n",
       "         857, 858, 859, 861, 863, 864, 865, 866, 867, 870, 871, 872, 873,\n",
       "         875, 877, 882, 883, 884, 885, 886, 887, 888, 889, 890]),\n",
       "  array([  1,  11,  13,  14,  15,  16,  19,  22,  40,  42,  44,  46,  49,\n",
       "          65,  74,  77,  86,  95,  97,  99, 101, 113, 119, 120, 140, 144,\n",
       "         147, 151, 152, 167, 168, 171, 174, 176, 178, 182, 185, 188, 193,\n",
       "         201, 205, 206, 210, 214, 215, 222, 232, 233, 236, 243, 245, 247,\n",
       "         248, 251, 262, 263, 264, 270, 274, 286, 290, 294, 306, 312, 314,\n",
       "         316, 321, 323, 325, 342, 345, 358, 364, 366, 376, 379, 383, 384,\n",
       "         391, 395, 398, 400, 408, 412, 414, 419, 425, 435, 443, 447, 451,\n",
       "         453, 464, 468, 470, 471, 472, 474, 478, 483, 495, 499, 502, 509,\n",
       "         511, 513, 523, 528, 535, 544, 545, 551, 552, 555, 556, 561, 573,\n",
       "         575, 580, 581, 583, 584, 590, 594, 599, 600, 602, 610, 611, 612,\n",
       "         623, 630, 632, 633, 644, 646, 651, 657, 662, 677, 702, 705, 709,\n",
       "         713, 717, 725, 728, 737, 740, 742, 744, 746, 748, 750, 762, 778,\n",
       "         779, 783, 785, 799, 802, 808, 816, 817, 837, 841, 845, 846, 860,\n",
       "         862, 868, 869, 874, 876, 878, 879, 880, 881])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   7,   8,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  21,  22,  24,  26,  27,  28,  29,  30,\n",
       "          31,  32,  34,  35,  36,  37,  38,  39,  40,  42,  43,  44,  45,\n",
       "          46,  48,  49,  50,  51,  55,  56,  57,  61,  62,  63,  64,  65,\n",
       "          67,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  82,\n",
       "          83,  84,  85,  86,  88,  89,  90,  91,  94,  95,  97,  99, 100,\n",
       "         101, 103, 105, 107, 108, 110, 111, 112, 113, 115, 116, 117, 118,\n",
       "         119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 134, 135, 136,\n",
       "         137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151,\n",
       "         152, 153, 154, 155, 156, 157, 158, 159, 161, 163, 167, 168, 169,\n",
       "         170, 171, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 185,\n",
       "         186, 187, 188, 190, 192, 193, 195, 196, 197, 198, 199, 201, 203,\n",
       "         204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
       "         217, 218, 219, 221, 222, 223, 224, 225, 227, 228, 230, 232, 233,\n",
       "         235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248,\n",
       "         249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263,\n",
       "         264, 267, 268, 269, 270, 271, 273, 274, 276, 277, 278, 279, 280,\n",
       "         281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 292, 293, 294,\n",
       "         295, 296, 297, 298, 299, 300, 301, 302, 303, 306, 307, 309, 310,\n",
       "         311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "         325, 326, 328, 329, 330, 331, 332, 334, 336, 337, 338, 339, 340,\n",
       "         341, 342, 344, 345, 346, 348, 350, 351, 352, 353, 354, 356, 357,\n",
       "         358, 361, 362, 364, 365, 366, 368, 369, 373, 374, 375, 376, 377,\n",
       "         379, 380, 381, 382, 383, 384, 385, 387, 388, 390, 391, 392, 393,\n",
       "         394, 395, 396, 398, 399, 400, 403, 404, 406, 407, 408, 409, 410,\n",
       "         411, 412, 413, 414, 416, 417, 418, 419, 422, 423, 424, 425, 426,\n",
       "         428, 429, 430, 431, 432, 433, 434, 435, 436, 438, 439, 440, 441,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "         455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 467, 468, 470,\n",
       "         471, 472, 473, 474, 475, 477, 478, 480, 481, 483, 484, 485, 487,\n",
       "         488, 489, 490, 491, 492, 494, 495, 496, 497, 499, 501, 502, 503,\n",
       "         504, 505, 506, 507, 509, 510, 511, 512, 513, 515, 516, 517, 518,\n",
       "         519, 520, 521, 522, 523, 525, 526, 527, 528, 530, 532, 535, 536,\n",
       "         537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568, 569, 570, 571, 573, 574, 575, 577, 580,\n",
       "         581, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594,\n",
       "         595, 596, 597, 599, 600, 601, 602, 603, 605, 606, 607, 608, 610,\n",
       "         611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 627,\n",
       "         629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
       "         642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 655,\n",
       "         656, 657, 658, 660, 661, 662, 663, 665, 669, 670, 672, 675, 676,\n",
       "         677, 678, 679, 680, 681, 683, 684, 687, 690, 692, 694, 695, 696,\n",
       "         698, 699, 700, 701, 702, 703, 705, 706, 708, 709, 710, 711, 712,\n",
       "         713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 725, 726, 727,\n",
       "         728, 729, 730, 731, 732, 737, 739, 740, 741, 742, 743, 744, 745,\n",
       "         746, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 761,\n",
       "         762, 763, 764, 765, 766, 767, 768, 769, 773, 775, 776, 777, 778,\n",
       "         779, 781, 782, 783, 784, 785, 786, 787, 789, 790, 791, 795, 798,\n",
       "         799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 810, 811, 812,\n",
       "         813, 815, 816, 817, 819, 820, 821, 823, 824, 825, 826, 827, 828,\n",
       "         829, 833, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846,\n",
       "         847, 848, 849, 850, 851, 852, 853, 854, 856, 857, 859, 860, 861,\n",
       "         862, 864, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877,\n",
       "         878, 879, 880, 881, 882, 883, 884, 886, 888, 889, 890]),\n",
       "  array([  6,   9,  10,  23,  25,  33,  41,  47,  52,  53,  54,  58,  59,\n",
       "          60,  66,  68,  69,  81,  87,  92,  93,  96,  98, 102, 104, 106,\n",
       "         109, 114, 127, 130, 131, 132, 133, 139, 150, 160, 162, 164, 165,\n",
       "         166, 172, 175, 183, 189, 191, 194, 200, 202, 220, 226, 229, 231,\n",
       "         234, 244, 259, 261, 265, 266, 272, 275, 291, 304, 305, 308, 324,\n",
       "         327, 333, 335, 343, 347, 349, 355, 359, 360, 363, 367, 370, 371,\n",
       "         372, 378, 386, 389, 397, 401, 402, 405, 415, 420, 421, 427, 437,\n",
       "         465, 466, 469, 476, 479, 482, 486, 493, 498, 500, 508, 514, 524,\n",
       "         529, 531, 533, 534, 547, 572, 576, 578, 579, 582, 598, 604, 609,\n",
       "         613, 624, 625, 626, 628, 654, 659, 664, 666, 667, 668, 671, 673,\n",
       "         674, 682, 685, 686, 688, 689, 691, 693, 697, 704, 707, 721, 724,\n",
       "         733, 734, 735, 736, 738, 747, 758, 760, 770, 771, 772, 774, 780,\n",
       "         788, 792, 793, 794, 796, 797, 809, 814, 818, 822, 830, 831, 832,\n",
       "         834, 838, 855, 858, 863, 865, 870, 885, 887])),\n",
       " (array([  0,   1,   2,   3,   4,   6,   7,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  19,  21,  22,  23,  25,  26,  27,  29,  31,  33,\n",
       "          34,  38,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
       "          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  65,\n",
       "          66,  67,  68,  69,  70,  71,  72,  74,  77,  79,  80,  81,  83,\n",
       "          85,  86,  87,  89,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
       "         100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113,\n",
       "         114, 116, 119, 120, 121, 122, 125, 126, 127, 128, 130, 131, 132,\n",
       "         133, 134, 135, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150,\n",
       "         151, 152, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "         166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179,\n",
       "         180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194,\n",
       "         195, 197, 198, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211,\n",
       "         213, 214, 215, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228,\n",
       "         229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244,\n",
       "         245, 247, 248, 250, 251, 252, 254, 255, 256, 257, 258, 259, 261,\n",
       "         262, 263, 264, 265, 266, 267, 268, 270, 272, 273, 274, 275, 278,\n",
       "         279, 280, 281, 282, 284, 286, 290, 291, 292, 293, 294, 295, 297,\n",
       "         298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 310, 312, 314,\n",
       "         315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327,\n",
       "         328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341,\n",
       "         342, 343, 344, 345, 346, 347, 349, 352, 354, 355, 356, 358, 359,\n",
       "         360, 361, 362, 363, 364, 366, 367, 369, 370, 371, 372, 373, 375,\n",
       "         376, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403,\n",
       "         404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
       "         418, 419, 420, 421, 423, 424, 425, 426, 427, 428, 429, 431, 434,\n",
       "         435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 447, 449, 450,\n",
       "         451, 453, 454, 455, 456, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "         466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "         479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 491, 492, 493,\n",
       "         495, 496, 498, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510,\n",
       "         511, 512, 513, 514, 515, 516, 518, 519, 522, 523, 524, 525, 527,\n",
       "         528, 529, 531, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542,\n",
       "         544, 545, 547, 548, 549, 550, 551, 552, 554, 555, 556, 558, 559,\n",
       "         561, 562, 563, 565, 568, 569, 571, 572, 573, 574, 575, 576, 577,\n",
       "         578, 579, 580, 581, 582, 583, 584, 585, 587, 588, 589, 590, 591,\n",
       "         592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
       "         605, 606, 607, 608, 609, 610, 611, 612, 613, 615, 616, 617, 618,\n",
       "         619, 623, 624, 625, 626, 628, 630, 631, 632, 633, 634, 635, 637,\n",
       "         638, 639, 640, 641, 642, 643, 644, 646, 647, 648, 649, 650, 651,\n",
       "         652, 654, 656, 657, 658, 659, 662, 663, 664, 665, 666, 667, 668,\n",
       "         670, 671, 673, 674, 675, 677, 681, 682, 685, 686, 687, 688, 689,\n",
       "         691, 693, 694, 695, 696, 697, 698, 701, 702, 703, 704, 705, 707,\n",
       "         708, 709, 710, 711, 713, 716, 717, 720, 721, 722, 723, 724, 725,\n",
       "         726, 728, 731, 732, 733, 734, 735, 736, 737, 738, 740, 741, 742,\n",
       "         744, 745, 746, 747, 748, 749, 750, 751, 752, 757, 758, 759, 760,\n",
       "         762, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 776, 778,\n",
       "         779, 780, 781, 783, 784, 785, 787, 788, 790, 792, 793, 794, 796,\n",
       "         797, 798, 799, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811,\n",
       "         812, 813, 814, 815, 816, 817, 818, 820, 821, 822, 826, 827, 828,\n",
       "         829, 830, 831, 832, 833, 834, 835, 837, 838, 841, 842, 844, 845,\n",
       "         846, 847, 848, 849, 850, 852, 853, 854, 855, 856, 858, 859, 860,\n",
       "         862, 863, 865, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877,\n",
       "         878, 879, 880, 881, 882, 883, 884, 885, 887, 889, 890]),\n",
       "  array([  5,   8,  18,  20,  24,  28,  30,  32,  35,  36,  37,  39,  63,\n",
       "          64,  73,  75,  76,  78,  82,  84,  88,  90, 110, 115, 117, 118,\n",
       "         123, 124, 129, 136, 137, 138, 141, 143, 153, 154, 173, 186, 190,\n",
       "         196, 199, 203, 209, 212, 216, 217, 225, 230, 240, 242, 246, 249,\n",
       "         253, 260, 269, 271, 276, 277, 283, 285, 287, 288, 289, 296, 300,\n",
       "         309, 311, 313, 334, 348, 350, 351, 353, 357, 365, 368, 374, 377,\n",
       "         399, 406, 422, 430, 432, 433, 440, 446, 448, 452, 457, 485, 490,\n",
       "         494, 497, 504, 505, 517, 520, 521, 526, 530, 532, 543, 546, 553,\n",
       "         557, 560, 564, 566, 567, 570, 586, 614, 620, 621, 622, 627, 629,\n",
       "         636, 645, 653, 655, 660, 661, 669, 672, 676, 678, 679, 680, 683,\n",
       "         684, 690, 692, 699, 700, 706, 712, 714, 715, 718, 719, 727, 729,\n",
       "         730, 739, 743, 753, 754, 755, 756, 761, 763, 764, 775, 777, 782,\n",
       "         786, 789, 791, 795, 800, 801, 819, 823, 824, 825, 836, 839, 840,\n",
       "         843, 851, 857, 861, 864, 866, 867, 886, 888])),\n",
       " (array([  1,   2,   3,   5,   6,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  22,  23,  24,  25,  26,  28,  29,  30,\n",
       "          32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  44,  45,\n",
       "          46,  47,  48,  49,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
       "          61,  62,  63,  64,  65,  66,  68,  69,  70,  72,  73,  74,  75,\n",
       "          76,  77,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  89,\n",
       "          90,  92,  93,  95,  96,  97,  98,  99, 101, 102, 104, 105, 106,\n",
       "         108, 109, 110, 112, 113, 114, 115, 117, 118, 119, 120, 123, 124,\n",
       "         125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138,\n",
       "         139, 140, 141, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154,\n",
       "         158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 171, 172, 173,\n",
       "         174, 175, 176, 177, 178, 182, 183, 185, 186, 187, 188, 189, 190,\n",
       "         191, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205,\n",
       "         206, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "         222, 223, 225, 226, 227, 229, 230, 231, 232, 233, 234, 236, 237,\n",
       "         238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         253, 255, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "         269, 270, 271, 272, 274, 275, 276, 277, 279, 283, 284, 285, 286,\n",
       "         287, 288, 289, 290, 291, 292, 294, 296, 297, 299, 300, 304, 305,\n",
       "         306, 308, 309, 311, 312, 313, 314, 315, 316, 318, 320, 321, 322,\n",
       "         323, 324, 325, 327, 328, 332, 333, 334, 335, 336, 337, 338, 341,\n",
       "         342, 343, 344, 345, 347, 348, 349, 350, 351, 353, 354, 355, 357,\n",
       "         358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371,\n",
       "         372, 373, 374, 376, 377, 378, 379, 380, 383, 384, 385, 386, 389,\n",
       "         391, 395, 397, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408,\n",
       "         409, 410, 412, 414, 415, 417, 418, 419, 420, 421, 422, 425, 427,\n",
       "         428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 440, 441, 442,\n",
       "         443, 446, 447, 448, 449, 450, 451, 452, 453, 457, 458, 460, 461,\n",
       "         463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, 476, 477,\n",
       "         478, 479, 480, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "         492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 504, 505,\n",
       "         506, 508, 509, 510, 511, 512, 513, 514, 517, 520, 521, 523, 524,\n",
       "         526, 528, 529, 530, 531, 532, 533, 534, 535, 536, 541, 543, 544,\n",
       "         545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "         559, 560, 561, 563, 564, 566, 567, 569, 570, 571, 572, 573, 575,\n",
       "         576, 578, 579, 580, 581, 582, 583, 584, 586, 588, 590, 592, 594,\n",
       "         597, 598, 599, 600, 602, 604, 605, 606, 607, 609, 610, 611, 612,\n",
       "         613, 614, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
       "         629, 630, 632, 633, 634, 635, 636, 637, 640, 641, 644, 645, 646,\n",
       "         647, 648, 650, 651, 652, 653, 654, 655, 657, 659, 660, 661, 662,\n",
       "         663, 664, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676,\n",
       "         677, 678, 679, 680, 682, 683, 684, 685, 686, 688, 689, 690, 691,\n",
       "         692, 693, 695, 696, 697, 698, 699, 700, 702, 703, 704, 705, 706,\n",
       "         707, 708, 709, 710, 712, 713, 714, 715, 716, 717, 718, 719, 720,\n",
       "         721, 722, 724, 725, 727, 728, 729, 730, 731, 732, 733, 734, 735,\n",
       "         736, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 749,\n",
       "         750, 751, 752, 753, 754, 755, 756, 757, 758, 760, 761, 762, 763,\n",
       "         764, 765, 766, 767, 769, 770, 771, 772, 774, 775, 776, 777, 778,\n",
       "         779, 780, 781, 782, 783, 784, 785, 786, 788, 789, 791, 792, 793,\n",
       "         794, 795, 796, 797, 799, 800, 801, 802, 803, 806, 808, 809, 814,\n",
       "         816, 817, 818, 819, 821, 822, 823, 824, 825, 826, 827, 830, 831,\n",
       "         832, 834, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846,\n",
       "         849, 850, 851, 852, 855, 857, 858, 859, 860, 861, 862, 863, 864,\n",
       "         865, 866, 867, 868, 869, 870, 872, 873, 874, 875, 876, 877, 878,\n",
       "         879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889]),\n",
       "  array([  0,   4,   7,  21,  27,  31,  43,  50,  51,  67,  71,  85,  91,\n",
       "          94, 100, 103, 107, 111, 116, 121, 122, 134, 142, 148, 149, 155,\n",
       "         156, 157, 161, 169, 170, 179, 180, 181, 184, 192, 198, 207, 208,\n",
       "         211, 224, 228, 235, 241, 252, 254, 256, 268, 273, 278, 280, 281,\n",
       "         282, 293, 295, 298, 301, 302, 303, 307, 310, 317, 319, 326, 329,\n",
       "         330, 331, 339, 340, 346, 352, 356, 361, 375, 381, 382, 387, 388,\n",
       "         390, 392, 393, 394, 396, 403, 411, 413, 416, 423, 424, 426, 434,\n",
       "         439, 444, 445, 454, 455, 456, 459, 462, 473, 475, 481, 503, 507,\n",
       "         515, 516, 518, 519, 522, 525, 527, 537, 538, 539, 540, 542, 550,\n",
       "         562, 565, 568, 574, 577, 585, 587, 589, 591, 593, 595, 596, 601,\n",
       "         603, 608, 615, 616, 617, 631, 638, 639, 642, 643, 649, 656, 658,\n",
       "         665, 681, 687, 694, 701, 711, 723, 726, 741, 759, 768, 773, 787,\n",
       "         790, 798, 804, 805, 807, 810, 811, 812, 813, 815, 820, 828, 829,\n",
       "         833, 835, 847, 848, 853, 854, 856, 871, 890]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## モデル\n",
    "* LightGBMを用いる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベースラインの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索しないハイパーパラメータ\n",
    "params_base = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": 123,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的関数\n",
    "def objective(trial):\n",
    "    # 探索するハイパーパラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,\n",
    "                 )\n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "    \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最適化処理（探索の実行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:10,488] A new study created in memory with name: no-name-d0817e16-e67a-43dd-b838-966a1974cb55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:10,909] Trial 0 finished with value: 0.7541711129244868 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.492522233779106, 'lambda_l2': 83.76388146302445}. Best is trial 0 with value: 0.7541711129244868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:11,291] Trial 1 finished with value: 0.7588600841127363 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.567922374174008, 'lambda_l2': 0.01732652966363563}. Best is trial 1 with value: 0.7588600841127363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:11,571] Trial 2 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102123, 'lambda_l2': 3.4482904089131434}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:11,866] Trial 3 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.2799978022399009, 'lambda_l2': 0.08185645330667264}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:12,134] Trial 4 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751797, 'lambda_l2': 0.5050346330980694}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:12,466] Trial 5 finished with value: 0.7519239219132509 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:12,619] Trial 6 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659076, 'lambda_l2': 1.1965765212602313}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:13,335] Trial 7 finished with value: 0.7642834724750486 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:13,604] Trial 8 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.206714812711709, 'lambda_l2': 3.1594683442464033}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.776580803025408e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.776580803025408e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.776580803025408e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.776580803025408e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.776580803025408e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.776580803025408e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:13,972] Trial 9 finished with value: 0.7822610005649364 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.776580803025408e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641542}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.776580803025408e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.776580803025408e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.776580803025408e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.776580803025408e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020104\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799442\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.920338990414188e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.920338990414188e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=18.289897792948295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18.289897792948295\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:14,206] Trial 10 finished with value: 0.716163454899253 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 200, 'min_sum_hessian_in_leaf': 8.920338990414188e-05, 'feature_fraction': 0.5040305717020104, 'bagging_fraction': 0.9940542446575642, 'lambda_l1': 0.010612397212799442, 'lambda_l2': 18.289897792948295}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020104\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799442\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.920338990414188e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.920338990414188e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=18.289897792948295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18.289897792948295\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020104\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799442\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.920338990414188e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.920338990414188e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=18.289897792948295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18.289897792948295\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020104\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799442\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.920338990414188e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.920338990414188e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=18.289897792948295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18.289897792948295\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020104\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799442\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.920338990414188e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.920338990414188e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=18.289897792948295, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18.289897792948295\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5850272097958577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5850272097958577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006685126747113572, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006685126747113572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5204920216297158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5204920216297158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07778945107272228, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07778945107272228\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:14,472] Trial 11 finished with value: 0.6386353650116126 and parameters: {'num_leaves': 243, 'min_data_in_leaf': 150, 'min_sum_hessian_in_leaf': 0.0006685126747113572, 'feature_fraction': 0.5850272097958577, 'bagging_fraction': 0.5204920216297158, 'lambda_l1': 6.343590915843685, 'lambda_l2': 0.07778945107272228}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5850272097958577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5850272097958577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006685126747113572, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006685126747113572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5204920216297158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5204920216297158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07778945107272228, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07778945107272228\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5850272097958577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5850272097958577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006685126747113572, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006685126747113572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5204920216297158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5204920216297158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07778945107272228, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07778945107272228\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5850272097958577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5850272097958577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006685126747113572, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006685126747113572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5204920216297158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5204920216297158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07778945107272228, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07778945107272228\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5850272097958577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5850272097958577\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.343590915843685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.343590915843685\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006685126747113572, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006685126747113572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5204920216297158, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5204920216297158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07778945107272228, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07778945107272228\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634109743354949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634109743354949\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09732674745359815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09732674745359815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005743102897337068, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005743102897337068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6568977276069294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6568977276069294\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01029965396374567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01029965396374567\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634109743354949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634109743354949\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09732674745359815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09732674745359815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005743102897337068, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005743102897337068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6568977276069294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6568977276069294\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01029965396374567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01029965396374567\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634109743354949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634109743354949\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09732674745359815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09732674745359815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005743102897337068, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005743102897337068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6568977276069294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6568977276069294\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01029965396374567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01029965396374567\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:14,865] Trial 12 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 256, 'min_data_in_leaf': 179, 'min_sum_hessian_in_leaf': 0.0005743102897337068, 'feature_fraction': 0.8634109743354949, 'bagging_fraction': 0.6568977276069294, 'lambda_l1': 0.09732674745359815, 'lambda_l2': 0.01029965396374567}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8634109743354949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634109743354949\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09732674745359815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09732674745359815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005743102897337068, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005743102897337068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6568977276069294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6568977276069294\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01029965396374567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01029965396374567\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634109743354949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634109743354949\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=179, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=179\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09732674745359815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09732674745359815\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005743102897337068, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005743102897337068\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6568977276069294, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6568977276069294\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01029965396374567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01029965396374567\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.398203621097178, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.398203621097178\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.0828053071219166e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.0828053071219166e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6116401896337238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6116401896337238\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18579132432411227, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18579132432411227\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.398203621097178, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.398203621097178\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.0828053071219166e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.0828053071219166e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6116401896337238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6116401896337238\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18579132432411227, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18579132432411227\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:15,112] Trial 13 finished with value: 0.7575418994413408 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 131, 'min_sum_hessian_in_leaf': 1.0828053071219166e-05, 'feature_fraction': 0.5018388179694605, 'bagging_fraction': 0.6116401896337238, 'lambda_l1': 8.398203621097178, 'lambda_l2': 0.18579132432411227}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.398203621097178, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.398203621097178\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.0828053071219166e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.0828053071219166e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6116401896337238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6116401896337238\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18579132432411227, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18579132432411227\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.398203621097178, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.398203621097178\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.0828053071219166e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.0828053071219166e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6116401896337238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6116401896337238\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18579132432411227, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18579132432411227\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5018388179694605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5018388179694605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.398203621097178, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.398203621097178\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.0828053071219166e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.0828053071219166e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6116401896337238, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6116401896337238\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18579132432411227, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18579132432411227\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825093053054962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825093053054962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16687286319156577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16687286319156577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00025111611178878413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00025111611178878413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704686734571154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704686734571154\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.433085314484019, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.433085314484019\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825093053054962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825093053054962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16687286319156577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16687286319156577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00025111611178878413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00025111611178878413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704686734571154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704686734571154\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.433085314484019, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.433085314484019\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825093053054962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825093053054962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16687286319156577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16687286319156577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00025111611178878413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00025111611178878413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704686734571154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704686734571154\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.433085314484019, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.433085314484019\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825093053054962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825093053054962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16687286319156577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16687286319156577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00025111611178878413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00025111611178878413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704686734571154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704686734571154\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.433085314484019, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.433085314484019\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825093053054962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825093053054962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=165, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=165\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16687286319156577, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16687286319156577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00025111611178878413, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00025111611178878413\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6704686734571154, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6704686734571154\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.433085314484019, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.433085314484019\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:15,429] Trial 14 finished with value: 0.7519239219132509 and parameters: {'num_leaves': 27, 'min_data_in_leaf': 165, 'min_sum_hessian_in_leaf': 0.00025111611178878413, 'feature_fraction': 0.6825093053054962, 'bagging_fraction': 0.6704686734571154, 'lambda_l1': 0.16687286319156577, 'lambda_l2': 6.433085314484019}. Best is trial 2 with value: 0.7867553825874083.\n",
      "[I 2023-10-29 21:03:15,662] Trial 15 finished with value: 0.750800326407633 and parameters: {'num_leaves': 138, 'min_data_in_leaf': 120, 'min_sum_hessian_in_leaf': 0.001215432268892957, 'feature_fraction': 0.5847432736056486, 'bagging_fraction': 0.5281566468339491, 'lambda_l1': 0.03848513214435228, 'lambda_l2': 0.5839440501965582}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5847432736056486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847432736056486\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03848513214435228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03848513214435228\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001215432268892957, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001215432268892957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5281566468339491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5281566468339491\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5839440501965582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5839440501965582\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847432736056486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847432736056486\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03848513214435228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03848513214435228\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001215432268892957, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001215432268892957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5281566468339491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5281566468339491\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5839440501965582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5839440501965582\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847432736056486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847432736056486\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03848513214435228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03848513214435228\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001215432268892957, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001215432268892957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5281566468339491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5281566468339491\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5839440501965582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5839440501965582\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847432736056486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847432736056486\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03848513214435228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03848513214435228\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001215432268892957, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001215432268892957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5281566468339491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5281566468339491\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5839440501965582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5839440501965582\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5847432736056486, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5847432736056486\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=120, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=120\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03848513214435228, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03848513214435228\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001215432268892957, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001215432268892957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5281566468339491, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5281566468339491\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5839440501965582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5839440501965582\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8281194759550805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8281194759550805\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35049776025647444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35049776025647444\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.308169236196065e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.308169236196065e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7996604755114874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996604755114874\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07096214030849714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07096214030849714\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8281194759550805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8281194759550805\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35049776025647444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35049776025647444\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.308169236196065e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.308169236196065e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7996604755114874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996604755114874\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07096214030849714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07096214030849714\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8281194759550805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8281194759550805\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35049776025647444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35049776025647444\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.308169236196065e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.308169236196065e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7996604755114874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996604755114874\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07096214030849714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07096214030849714\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8281194759550805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8281194759550805\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35049776025647444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35049776025647444\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.308169236196065e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.308169236196065e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7996604755114874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996604755114874\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07096214030849714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07096214030849714\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8281194759550805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8281194759550805\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.35049776025647444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.35049776025647444\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6.308169236196065e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6.308169236196065e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7996604755114874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7996604755114874\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07096214030849714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07096214030849714\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:16,435] Trial 16 finished with value: 0.7227104387671834 and parameters: {'num_leaves': 216, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 6.308169236196065e-05, 'feature_fraction': 0.8281194759550805, 'bagging_fraction': 0.7996604755114874, 'lambda_l1': 0.35049776025647444, 'lambda_l2': 0.07096214030849714}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.93890695089651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93890695089651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=191, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4242686509049345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4242686509049345\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00029213848222772206, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00029213848222772206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7017228274653975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7017228274653975\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4478620870734111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4478620870734111\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93890695089651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93890695089651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=191, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4242686509049345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4242686509049345\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00029213848222772206, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00029213848222772206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7017228274653975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7017228274653975\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4478620870734111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4478620870734111\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93890695089651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93890695089651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=191, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4242686509049345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4242686509049345\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00029213848222772206, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00029213848222772206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7017228274653975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7017228274653975\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4478620870734111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4478620870734111\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:16,802] Trial 17 finished with value: 0.7755194275312285 and parameters: {'num_leaves': 127, 'min_data_in_leaf': 191, 'min_sum_hessian_in_leaf': 0.00029213848222772206, 'feature_fraction': 0.93890695089651, 'bagging_fraction': 0.7017228274653975, 'lambda_l1': 1.4242686509049345, 'lambda_l2': 0.4478620870734111}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.93890695089651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93890695089651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=191, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4242686509049345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4242686509049345\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00029213848222772206, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00029213848222772206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7017228274653975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7017228274653975\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4478620870734111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4478620870734111\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93890695089651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93890695089651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=191, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4242686509049345, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4242686509049345\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00029213848222772206, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00029213848222772206\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7017228274653975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7017228274653975\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4478620870734111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4478620870734111\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.741012426616628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741012426616628\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=153, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=153\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8030387388559193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8030387388559193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001402088130472093, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001402088130472093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.612176646078341, subsample=1.0 will be ignored. Current value: bagging_fraction=0.612176646078341\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.372294855684903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.372294855684903\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:17,059] Trial 18 finished with value: 0.7159688657334756 and parameters: {'num_leaves': 64, 'min_data_in_leaf': 153, 'min_sum_hessian_in_leaf': 0.0001402088130472093, 'feature_fraction': 0.741012426616628, 'bagging_fraction': 0.612176646078341, 'lambda_l1': 0.8030387388559193, 'lambda_l2': 5.372294855684903}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.741012426616628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741012426616628\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=153, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=153\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8030387388559193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8030387388559193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001402088130472093, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001402088130472093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.612176646078341, subsample=1.0 will be ignored. Current value: bagging_fraction=0.612176646078341\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.372294855684903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.372294855684903\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.741012426616628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741012426616628\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=153, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=153\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8030387388559193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8030387388559193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001402088130472093, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001402088130472093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.612176646078341, subsample=1.0 will be ignored. Current value: bagging_fraction=0.612176646078341\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.372294855684903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.372294855684903\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.741012426616628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741012426616628\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=153, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=153\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8030387388559193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8030387388559193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001402088130472093, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001402088130472093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.612176646078341, subsample=1.0 will be ignored. Current value: bagging_fraction=0.612176646078341\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.372294855684903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.372294855684903\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.741012426616628, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.741012426616628\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=153, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=153\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8030387388559193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8030387388559193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0001402088130472093, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0001402088130472093\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.612176646078341, subsample=1.0 will be ignored. Current value: bagging_fraction=0.612176646078341\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.372294855684903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.372294855684903\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9050192251205349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050192251205349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20767859726212454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20767859726212454\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017255827970869692, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017255827970869692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680242926216419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5680242926216419\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1743561635328021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1743561635328021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9050192251205349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050192251205349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20767859726212454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20767859726212454\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017255827970869692, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017255827970869692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680242926216419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5680242926216419\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1743561635328021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1743561635328021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9050192251205349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050192251205349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20767859726212454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20767859726212454\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017255827970869692, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017255827970869692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680242926216419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5680242926216419\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1743561635328021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1743561635328021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9050192251205349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050192251205349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20767859726212454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20767859726212454\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017255827970869692, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017255827970869692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680242926216419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5680242926216419\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1743561635328021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1743561635328021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9050192251205349, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9050192251205349\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20767859726212454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20767859726212454\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0017255827970869692, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0017255827970869692\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5680242926216419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5680242926216419\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1743561635328021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1743561635328021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:17,342] Trial 19 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 204, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0017255827970869692, 'feature_fraction': 0.9050192251205349, 'bagging_fraction': 0.5680242926216419, 'lambda_l1': 0.20767859726212454, 'lambda_l2': 1.1743561635328021}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.83128840684204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83128840684204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030654691807557245, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030654691807557245\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005615868726974036, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005615868726974036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6843014804540657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6843014804540657\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0429279051193992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0429279051193992\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83128840684204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83128840684204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030654691807557245, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030654691807557245\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005615868726974036, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005615868726974036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6843014804540657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6843014804540657\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0429279051193992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0429279051193992\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:17,956] Trial 20 finished with value: 0.7330173874835226 and parameters: {'num_leaves': 152, 'min_data_in_leaf': 63, 'min_sum_hessian_in_leaf': 0.0005615868726974036, 'feature_fraction': 0.83128840684204, 'bagging_fraction': 0.6843014804540657, 'lambda_l1': 0.030654691807557245, 'lambda_l2': 0.0429279051193992}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.83128840684204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83128840684204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030654691807557245, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030654691807557245\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005615868726974036, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005615868726974036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6843014804540657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6843014804540657\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0429279051193992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0429279051193992\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83128840684204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83128840684204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030654691807557245, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030654691807557245\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005615868726974036, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005615868726974036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6843014804540657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6843014804540657\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0429279051193992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0429279051193992\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83128840684204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83128840684204\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.030654691807557245, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.030654691807557245\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0005615868726974036, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0005615868726974036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6843014804540657, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6843014804540657\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0429279051193992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0429279051193992\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717234697124583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717234697124583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=142, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=142\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0456517316541138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0456517316541138\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.915555273944388e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.915555273944388e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7187026569751934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7187026569751934\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.345790157472468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.345790157472468\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717234697124583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717234697124583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=142, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=142\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0456517316541138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0456517316541138\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.915555273944388e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.915555273944388e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7187026569751934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7187026569751934\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.345790157472468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.345790157472468\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717234697124583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717234697124583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=142, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=142\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0456517316541138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0456517316541138\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.915555273944388e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.915555273944388e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7187026569751934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7187026569751934\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.345790157472468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.345790157472468\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717234697124583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717234697124583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=142, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=142\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0456517316541138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0456517316541138\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.915555273944388e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.915555273944388e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7187026569751934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7187026569751934\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.345790157472468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.345790157472468\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.717234697124583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.717234697124583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=142, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=142\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0456517316541138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0456517316541138\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.915555273944388e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.915555273944388e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7187026569751934, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7187026569751934\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.345790157472468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.345790157472468\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:18,194] Trial 21 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 57, 'min_data_in_leaf': 142, 'min_sum_hessian_in_leaf': 3.915555273944388e-05, 'feature_fraction': 0.717234697124583, 'bagging_fraction': 0.7187026569751934, 'lambda_l1': 1.0456517316541138, 'lambda_l2': 0.345790157472468}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7097128253270057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097128253270057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5082139072171981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5082139072171981\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.527352002561534e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.527352002561534e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7163989045903905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7163989045903905\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15713254479051275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15713254479051275\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7097128253270057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097128253270057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5082139072171981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5082139072171981\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.527352002561534e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.527352002561534e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7163989045903905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7163989045903905\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15713254479051275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15713254479051275\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7097128253270057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097128253270057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5082139072171981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5082139072171981\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.527352002561534e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.527352002561534e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7163989045903905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7163989045903905\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15713254479051275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15713254479051275\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7097128253270057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097128253270057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5082139072171981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5082139072171981\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.527352002561534e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.527352002561534e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7163989045903905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7163989045903905\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15713254479051275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15713254479051275\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:18,475] Trial 22 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 116, 'min_data_in_leaf': 121, 'min_sum_hessian_in_leaf': 2.527352002561534e-05, 'feature_fraction': 0.7097128253270057, 'bagging_fraction': 0.7163989045903905, 'lambda_l1': 0.5082139072171981, 'lambda_l2': 0.15713254479051275}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7097128253270057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7097128253270057\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=121, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=121\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5082139072171981, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5082139072171981\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.527352002561534e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.527352002561534e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7163989045903905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7163989045903905\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15713254479051275, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15713254479051275\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788761423267231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788761423267231\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=157, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=157\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.601664292282324, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.601664292282324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.01501827040368e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.01501827040368e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6545353244312025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6545353244312025\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6316387258745321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6316387258745321\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788761423267231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788761423267231\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=157, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=157\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.601664292282324, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.601664292282324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.01501827040368e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.01501827040368e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6545353244312025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6545353244312025\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6316387258745321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6316387258745321\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:18,788] Trial 23 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 96, 'min_data_in_leaf': 157, 'min_sum_hessian_in_leaf': 1.01501827040368e-05, 'feature_fraction': 0.788761423267231, 'bagging_fraction': 0.6545353244312025, 'lambda_l1': 1.601664292282324, 'lambda_l2': 0.6316387258745321}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.788761423267231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788761423267231\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=157, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=157\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.601664292282324, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.601664292282324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.01501827040368e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.01501827040368e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6545353244312025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6545353244312025\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6316387258745321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6316387258745321\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788761423267231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788761423267231\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=157, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=157\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.601664292282324, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.601664292282324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.01501827040368e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.01501827040368e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6545353244312025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6545353244312025\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6316387258745321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6316387258745321\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.788761423267231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.788761423267231\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=157, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=157\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.601664292282324, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.601664292282324\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.01501827040368e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.01501827040368e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6545353244312025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6545353244312025\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.6316387258745321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.6316387258745321\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9996311567105678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9996311567105678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16897778747758307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16897778747758307\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.39707589308838e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.39707589308838e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7777958439193616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7777958439193616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2956512946370067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2956512946370067\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:19,071] Trial 24 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 67, 'min_data_in_leaf': 178, 'min_sum_hessian_in_leaf': 2.39707589308838e-05, 'feature_fraction': 0.9996311567105678, 'bagging_fraction': 0.7777958439193616, 'lambda_l1': 0.16897778747758307, 'lambda_l2': 0.2956512946370067}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9996311567105678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9996311567105678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16897778747758307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16897778747758307\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.39707589308838e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.39707589308838e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7777958439193616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7777958439193616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2956512946370067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2956512946370067\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9996311567105678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9996311567105678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16897778747758307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16897778747758307\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.39707589308838e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.39707589308838e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7777958439193616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7777958439193616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2956512946370067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2956512946370067\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9996311567105678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9996311567105678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16897778747758307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16897778747758307\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.39707589308838e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.39707589308838e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7777958439193616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7777958439193616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2956512946370067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2956512946370067\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9996311567105678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9996311567105678\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=178, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=178\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16897778747758307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16897778747758307\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=2.39707589308838e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=2.39707589308838e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7777958439193616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7777958439193616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2956512946370067, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2956512946370067\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6499234858545734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499234858545734\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8090488693339095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8090488693339095\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.487882337152676e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.487882337152676e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7309054283754788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7309054283754788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1626919405799148, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1626919405799148\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6499234858545734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499234858545734\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8090488693339095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8090488693339095\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.487882337152676e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.487882337152676e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7309054283754788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7309054283754788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1626919405799148, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1626919405799148\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6499234858545734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499234858545734\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8090488693339095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8090488693339095\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.487882337152676e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.487882337152676e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7309054283754788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7309054283754788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1626919405799148, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1626919405799148\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6499234858545734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499234858545734\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8090488693339095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8090488693339095\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.487882337152676e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.487882337152676e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7309054283754788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7309054283754788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1626919405799148, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1626919405799148\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:19,403] Trial 25 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 47, 'min_data_in_leaf': 131, 'min_sum_hessian_in_leaf': 8.487882337152676e-05, 'feature_fraction': 0.6499234858545734, 'bagging_fraction': 0.7309054283754788, 'lambda_l1': 3.8090488693339095, 'lambda_l2': 1.1626919405799148}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6499234858545734, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6499234858545734\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=131, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=131\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8090488693339095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8090488693339095\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.487882337152676e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.487882337152676e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7309054283754788, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7309054283754788\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1626919405799148, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1626919405799148\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347599648632755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347599648632755\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7404512199588413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7404512199588413\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.047888403355595e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.047888403355595e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6906680173840315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906680173840315\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07075679412507242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07075679412507242\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347599648632755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347599648632755\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7404512199588413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7404512199588413\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.047888403355595e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.047888403355595e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6906680173840315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906680173840315\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07075679412507242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07075679412507242\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347599648632755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347599648632755\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7404512199588413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7404512199588413\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.047888403355595e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.047888403355595e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6906680173840315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906680173840315\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07075679412507242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07075679412507242\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347599648632755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347599648632755\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7404512199588413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7404512199588413\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.047888403355595e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.047888403355595e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6906680173840315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906680173840315\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07075679412507242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07075679412507242\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347599648632755, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347599648632755\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=93, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=93\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7404512199588413, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7404512199588413\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.047888403355595e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.047888403355595e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6906680173840315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906680173840315\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07075679412507242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07075679412507242\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:19,809] Trial 26 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 10, 'min_data_in_leaf': 93, 'min_sum_hessian_in_leaf': 4.047888403355595e-05, 'feature_fraction': 0.7347599648632755, 'bagging_fraction': 0.6906680173840315, 'lambda_l1': 0.7404512199588413, 'lambda_l2': 0.07075679412507242}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8270010486440649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270010486440649\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3269580935097336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3269580935097336\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.5675552319385728e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.5675552319385728e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5642713113720017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5642713113720017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.799520459204495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.799520459204495\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8270010486440649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270010486440649\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3269580935097336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3269580935097336\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.5675552319385728e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.5675552319385728e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5642713113720017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5642713113720017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.799520459204495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.799520459204495\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8270010486440649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270010486440649\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3269580935097336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3269580935097336\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.5675552319385728e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.5675552319385728e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5642713113720017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5642713113720017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.799520459204495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.799520459204495\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8270010486440649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270010486440649\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3269580935097336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3269580935097336\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.5675552319385728e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.5675552319385728e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5642713113720017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5642713113720017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.799520459204495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.799520459204495\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8270010486440649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8270010486440649\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3269580935097336, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3269580935097336\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.5675552319385728e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.5675552319385728e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5642713113720017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5642713113720017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.799520459204495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.799520459204495\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:20,063] Trial 27 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 110, 'min_sum_hessian_in_leaf': 1.5675552319385728e-05, 'feature_fraction': 0.8270010486440649, 'bagging_fraction': 0.5642713113720017, 'lambda_l1': 0.3269580935097336, 'lambda_l2': 0.799520459204495}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7568074608774176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7568074608774176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9953208739743914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9953208739743914\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007707394018185613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007707394018185613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079390078064106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079390078064106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28022987043123815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28022987043123815\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7568074608774176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7568074608774176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9953208739743914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9953208739743914\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007707394018185613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007707394018185613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079390078064106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079390078064106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28022987043123815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28022987043123815\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7568074608774176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7568074608774176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9953208739743914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9953208739743914\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007707394018185613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007707394018185613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079390078064106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079390078064106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28022987043123815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28022987043123815\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7568074608774176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7568074608774176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9953208739743914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9953208739743914\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007707394018185613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007707394018185613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079390078064106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079390078064106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28022987043123815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28022987043123815\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7568074608774176, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7568074608774176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9953208739743914, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9953208739743914\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.007707394018185613, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.007707394018185613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8079390078064106, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8079390078064106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28022987043123815, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28022987043123815\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:20,293] Trial 28 finished with value: 0.6800138095537003 and parameters: {'num_leaves': 138, 'min_data_in_leaf': 74, 'min_sum_hessian_in_leaf': 0.007707394018185613, 'feature_fraction': 0.7568074608774176, 'bagging_fraction': 0.8079390078064106, 'lambda_l1': 0.9953208739743914, 'lambda_l2': 0.28022987043123815}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6984804982745697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984804982745697\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=145, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=145\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4224534932644461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4224534932644461\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.216329135917105e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.216329135917105e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6397548071515035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6397548071515035\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.64848046417389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.64848046417389\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984804982745697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984804982745697\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=145, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=145\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4224534932644461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4224534932644461\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.216329135917105e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.216329135917105e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6397548071515035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6397548071515035\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.64848046417389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.64848046417389\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984804982745697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984804982745697\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=145, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=145\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4224534932644461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4224534932644461\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.216329135917105e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.216329135917105e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6397548071515035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6397548071515035\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.64848046417389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.64848046417389\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6984804982745697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984804982745697\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=145, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=145\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4224534932644461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4224534932644461\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.216329135917105e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.216329135917105e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6397548071515035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6397548071515035\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.64848046417389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.64848046417389\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-29 21:03:20,543] Trial 29 finished with value: 0.7867553825874083 and parameters: {'num_leaves': 76, 'min_data_in_leaf': 145, 'min_sum_hessian_in_leaf': 3.216329135917105e-05, 'feature_fraction': 0.6984804982745697, 'bagging_fraction': 0.6397548071515035, 'lambda_l1': 0.4224534932644461, 'lambda_l2': 16.64848046417389}. Best is trial 2 with value: 0.7867553825874083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6984804982745697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984804982745697\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=145, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=145\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.4224534932644461, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4224534932644461\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.216329135917105e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.216329135917105e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6397548071515035, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6397548071515035\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.64848046417389, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.64848046417389\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.7868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 107,\n",
       " 'min_data_in_leaf': 149,\n",
       " 'min_sum_hessian_in_leaf': 3.52756635172055e-05,\n",
       " 'feature_fraction': 0.5877258780737462,\n",
       " 'bagging_fraction': 0.7657756869209191,\n",
       " 'lambda_l1': 1.3406343673102123,\n",
       " 'lambda_l2': 3.4482904089131434}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"acc(best)={:.4f}\".format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMのハイパーパラメータ\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'n_estimators': 100000,\n",
    "    \"random_state\": 123,\n",
    "    \"importance_type\": \"gain\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': 0.1,\n",
       " 'num_leaves': 107,\n",
       " 'n_estimators': 100000,\n",
       " 'random_state': 123,\n",
       " 'importance_type': 'gain',\n",
       " 'min_data_in_leaf': 149,\n",
       " 'min_sum_hessian_in_leaf': 3.52756635172055e-05,\n",
       " 'feature_fraction': 0.5877258780737462,\n",
       " 'bagging_fraction': 0.7657756869209191,\n",
       " 'lambda_l1': 1.3406343673102123,\n",
       " 'lambda_l2': 3.4482904089131434}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.update(trial.params)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv(input_x,\n",
    "             input_y,\n",
    "             input_id,\n",
    "             params,\n",
    "             n_splits=5,\n",
    "            ):\n",
    "    \n",
    "    # 結果格納用\n",
    "    metrics = []\n",
    "    imp = pd.DataFrame()\n",
    "    model_list = []\n",
    "\n",
    "    # K分割検証法で学習用と検証用に分ける\n",
    "    cv = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123).split(input_x, input_y))\n",
    "\n",
    "    # ループ回数分 LightGBMを試す\n",
    "    for nfold in np.arange(n_splits):\n",
    "        # 区切り線\n",
    "        print(\"-\"*20, nfold, \"-\"*20)\n",
    "\n",
    "        # 学習データ、検証データのインデックスを取得\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        \n",
    "        # インデックスのデータを取得\n",
    "        x_tr, y_tr = input_x.loc[idx_tr, :], input_y.loc[idx_tr, :]\n",
    "        x_va, y_va = input_x.loc[idx_va, :], input_y.loc[idx_va, :]\n",
    "        print(\"x_train\", x_tr.shape, \"y_valid\", y_tr.shape)\n",
    "        print(\"x_valid\", x_va.shape, \"y_valid\", y_va.shape)\n",
    "\n",
    "        # Yデータの偏り確認\n",
    "        print(\"y_train:{:.3f}, y_tr:{:.3f}, y_va:{:.3f}\".format(\n",
    "            input_y[\"Survived\"].mean(),\n",
    "            y_tr[\"Survived\"].mean(),\n",
    "            y_va[\"Survived\"].mean(),\n",
    "        ))\n",
    "\n",
    "        # LightGBMモデル作成\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=100,\n",
    "                 )\n",
    "        model_list.append(model)\n",
    "\n",
    "        # 推論\n",
    "        y_tr_pred = model.predict(x_tr)\n",
    "        y_va_pred = model.predict(x_va)\n",
    "        \n",
    "        # 正解と予測から正解率を算出\n",
    "        metric_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "        metric_va = accuracy_score(y_va, y_va_pred)\n",
    "        print(\"[accuracy] tr: {:.2f}, va: {:.2f}\".format(metric_tr, metric_va))    \n",
    "\n",
    "        # 全体結果に格納\n",
    "        metrics.append([nfold, metric_tr, metric_va])\n",
    "        \n",
    "        # 重要度の記録\n",
    "        _imp = pd.DataFrame({\"col\":input_x.columns, \"imp\":model.feature_importances_, \"nfold\":nfold})\n",
    "        imp = pd.concat([imp, _imp], axis=0, ignore_index=True)\n",
    "\n",
    "    # まとめ結果を表示\n",
    "    print(\"-\"*20, \"result\", \"-\"*20)\n",
    "    metrics = np.array(metrics)\n",
    "    print(metrics)\n",
    "\n",
    "    # 正確性の平均、偏差\n",
    "    print(\"[cv ] tr: {:.2f}+-{:.2f}, va: {:.2f}+-{:.2f}\".format(\n",
    "        metrics[:,1].mean(), metrics[:,1].std(),\n",
    "        metrics[:,2].mean(), metrics[:,2].std(),\n",
    "    ))\n",
    "\n",
    "    # 重要度の平均偏差\n",
    "    imp = imp.groupby(\"col\")[\"imp\"].agg([\"mean\", \"std\"])\n",
    "    imp.columns = [\"imp\", \"imp_std\"]\n",
    "    imp = imp.reset_index(drop=False)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    \n",
    "    return imp, metrics, model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0 --------------------\n",
      "x_train (712, 4) y_valid (712, 1)\n",
      "x_valid (179, 4) y_valid (179, 1)\n",
      "y_train:0.384, y_tr:0.383, y_va:0.385\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[100]\ttraining's auc: 0.857026\tvalid_1's auc: 0.805072\n",
      "[accuracy] tr: 0.79, va: 0.79\n",
      "-------------------- 1 --------------------\n",
      "x_train (713, 4) y_valid (713, 1)\n",
      "x_valid (178, 4) y_valid (178, 1)\n",
      "y_train:0.384, y_tr:0.384, y_va:0.382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[100]\ttraining's auc: 0.850918\tvalid_1's auc: 0.820922\n",
      "[accuracy] tr: 0.79, va: 0.76\n",
      "-------------------- 2 --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (713, 4) y_valid (713, 1)\n",
      "x_valid (178, 4) y_valid (178, 1)\n",
      "y_train:0.384, y_tr:0.384, y_va:0.382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[100]\ttraining's auc: 0.847991\tvalid_1's auc: 0.838636\n",
      "[accuracy] tr: 0.78, va: 0.80\n",
      "-------------------- 3 --------------------\n",
      "x_train (713, 4) y_valid (713, 1)\n",
      "x_valid (178, 4) y_valid (178, 1)\n",
      "y_train:0.384, y_tr:0.384, y_va:0.382\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[100]\ttraining's auc: 0.849068\tvalid_1's auc: 0.859358\n",
      "[accuracy] tr: 0.79, va: 0.79\n",
      "-------------------- 4 --------------------\n",
      "x_train (713, 4) y_valid (713, 1)\n",
      "x_valid (178, 4) y_valid (178, 1)\n",
      "y_train:0.384, y_tr:0.383, y_va:0.388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[100]\ttraining's auc: 0.845001\tvalid_1's auc: 0.863715\n",
      "[accuracy] tr: 0.79, va: 0.79\n",
      "-------------------- result --------------------\n",
      "[[0.         0.78651685 0.7877095 ]\n",
      " [1.         0.79242637 0.76404494]\n",
      " [2.         0.78401122 0.79775281]\n",
      " [3.         0.78541374 0.79213483]\n",
      " [4.         0.78541374 0.79213483]]\n",
      "[cv ] tr: 0.79+-0.00, va: 0.79+-0.01\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# CV実行\n",
    "imp, metrics, model_list = train_cv(x_train, y_train, id_train, params, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "      <th>imp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>761.003072</td>\n",
       "      <td>46.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>325.901290</td>\n",
       "      <td>24.337061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>260.195238</td>\n",
       "      <td>35.713838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>71.360444</td>\n",
       "      <td>31.700849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          col         imp    imp_std\n",
       "0  Sex_female  761.003072  46.443744\n",
       "1    Sex_male  325.901290  24.337061\n",
       "2      Pclass  260.195238  35.713838\n",
       "3        Fare   71.360444  31.700849"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(\"imp\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Sex_female  418 non-null    int64  \n",
      " 1   Sex_male    418 non-null    int64  \n",
      " 2   Pclass      418 non-null    int64  \n",
      " 3   Fare        417 non-null    float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 13.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_sex_test = pd.get_dummies(df_test[[\"Sex\"]], dummy_na=False, drop_first=False)\n",
    "df_sex_test = df_sex_test.astype(np.int64)\n",
    "x_test = pd.concat([df_sex_test, df_test[[\"Pclass\", \"Fare\"]]], axis=1)\n",
    "id_test = df_test[[\"PassengerId\"]]\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_model</th>\n",
       "      <th>1_model</th>\n",
       "      <th>2_model</th>\n",
       "      <th>3_model</th>\n",
       "      <th>4_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0_model  1_model  2_model  3_model  4_model\n",
       "0          0        0        0        0        0\n",
       "1          1        1        1        1        1\n",
       "2          0        0        0        0        0\n",
       "3          0        0        0        0        0\n",
       "4          1        1        1        1        1\n",
       "..       ...      ...      ...      ...      ...\n",
       "413        0        0        0        0        0\n",
       "414        1        1        1        1        1\n",
       "415        0        0        0        0        0\n",
       "416        0        0        0        0        0\n",
       "417        0        0        0        0        0\n",
       "\n",
       "[418 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 結果を辞書に保存\n",
    "solution = {}\n",
    " \n",
    "# 各モデルで予測\n",
    "for i, model in enumerate(model_list):\n",
    "    test_pred = model.predict(x_test)\n",
    "    solution[str(i) + \"_model\"] = test_pred\n",
    "\n",
    "# 辞書からDataFrameに変更\n",
    "solution = pd.DataFrame(solution)\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\WorkSpace\\Kaggle\\titanic\\nb\\001_base.ipynb Cell 57\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WorkSpace/Kaggle/titanic/nb/001_base.ipynb#Y110sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m solution_max \u001b[39m=\u001b[39m solution\u001b[39m.\u001b[39mmode(axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WorkSpace/Kaggle/titanic/nb/001_base.ipynb#Y110sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(solution_max)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/WorkSpace/Kaggle/titanic/nb/001_base.ipynb#Y110sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(solution_max\u001b[39m.\u001b[39mshape())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# 多数決 (最頻値)を取得\n",
    "solution_max = solution.mode(axis = 1).values\n",
    "\n",
    "print(solution_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerIdを取得\n",
    "PassengerId = np.array(df_test[\"PassengerId\"]).astype(int)\n",
    " \n",
    "# my_prediction(予測データ）とPassengerIdをデータフレームへ落とし込む\n",
    "my_solution = pd.DataFrame(solution_max.astype(int), index = PassengerId, columns = [\"Survived\"])\n",
    " \n",
    "# my_tree_one.csvとして書き出し\n",
    "my_solution.to_csv(\"../data/output/001/submission.csv\", index_label = [\"PassengerId\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
